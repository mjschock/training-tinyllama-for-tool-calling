{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2022787",
   "metadata": {
    "papermill": {
     "duration": 0.025057,
     "end_time": "2024-11-29T18:37:54.479929",
     "exception": false,
     "start_time": "2024-11-29T18:37:54.454872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training TinyLlama for Tool-calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cfc08b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:37:54.536893Z",
     "iopub.status.busy": "2024-11-29T18:37:54.536417Z",
     "iopub.status.idle": "2024-11-29T18:38:02.070898Z",
     "shell.execute_reply": "2024-11-29T18:38:02.069986Z"
    },
    "papermill": {
     "duration": 7.567923,
     "end_time": "2024-11-29T18:38:02.072676",
     "exception": false,
     "start_time": "2024-11-29T18:37:54.504753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in local environment\n",
      "Found requirements.txt at: /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring appnope: markers 'python_version >= \"3.10\" and python_version < \"4.0\" and platform_system == \"Darwin\"' don't match your environment\r\n",
      "Ignoring pywin32: markers 'python_version >= \"3.10\" and python_version < \"4.0\" and sys_platform == \"win32\"' don't match your environment\r\n",
      "Ignoring pywinpty: markers 'python_version >= \"3.10\" and python_version < \"4.0\" and os_name == \"nt\"' don't match your environment\r\n",
      "Ignoring waitress: markers 'python_version >= \"3.10\" and python_version < \"4.0\" and platform_system == \"Windows\"' don't match your environment\r\n",
      "Requirement already satisfied: absl-py==2.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 1)) (2.1.0)\r\n",
      "Requirement already satisfied: accelerate==1.1.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 2)) (1.1.1)\r\n",
      "Requirement already satisfied: aiohappyeyeballs==2.4.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 3)) (2.4.3)\r\n",
      "Requirement already satisfied: aiohttp-cors==0.7.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 4)) (0.7.0)\r\n",
      "Requirement already satisfied: aiohttp==3.11.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 5)) (3.11.2)\r\n",
      "Requirement already satisfied: aiosignal==1.3.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 6)) (1.3.1)\r\n",
      "Requirement already satisfied: aiosqlite==0.20.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 7)) (0.20.0)\r\n",
      "Requirement already satisfied: alembic==1.14.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 8)) (1.14.0)\r\n",
      "Requirement already satisfied: annotated-types==0.7.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 9)) (0.7.0)\r\n",
      "Requirement already satisfied: ansicolors==1.1.8 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 10)) (1.1.8)\r\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 11)) (4.9.3)\r\n",
      "Requirement already satisfied: anyio==4.6.2.post1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 12)) (4.6.2.post1)\r\n",
      "Requirement already satisfied: appdirs==1.4.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 13)) (1.4.4)\r\n",
      "Requirement already satisfied: apprise==1.9.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 15)) (1.9.0)\r\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 16)) (21.2.0)\r\n",
      "Requirement already satisfied: argon2-cffi==23.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 17)) (23.1.0)\r\n",
      "Requirement already satisfied: arrow==1.3.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 18)) (1.3.0)\r\n",
      "Requirement already satisfied: asgi-lifespan==2.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 19)) (2.1.0)\r\n",
      "Requirement already satisfied: asgiref==3.8.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 20)) (3.8.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==2.4.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 21)) (2.4.1)\r\n",
      "Requirement already satisfied: async-lru==2.0.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 22)) (2.0.4)\r\n",
      "Requirement already satisfied: async-timeout==5.0.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 23)) (5.0.1)\r\n",
      "Requirement already satisfied: asyncpg==0.30.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 24)) (0.30.0)\r\n",
      "Requirement already satisfied: attrs==24.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 25)) (24.2.0)\r\n",
      "Requirement already satisfied: babel==2.16.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 26)) (2.16.0)\r\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 27)) (4.12.3)\r\n",
      "Requirement already satisfied: bert-score==0.3.13 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 28)) (0.3.13)\r\n",
      "Requirement already satisfied: binaryornot==0.4.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 29)) (0.4.4)\r\n",
      "Requirement already satisfied: bitsandbytes==0.44.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 30)) (0.44.1)\r\n",
      "Requirement already satisfied: black==24.10.0 in ./.venv/lib/python3.10/site-packages (from black[jupyter]==24.10.0->-r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 31)) (24.10.0)\r\n",
      "Requirement already satisfied: bleach==6.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 32)) (6.2.0)\r\n",
      "Requirement already satisfied: blinker==1.9.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 33)) (1.9.0)\r\n",
      "Requirement already satisfied: blobfile==3.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 34)) (3.0.0)\r\n",
      "Requirement already satisfied: build==1.2.2.post1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 35)) (1.2.2.post1)\r\n",
      "Requirement already satisfied: cachetools==5.5.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 36)) (5.5.0)\r\n",
      "Requirement already satisfied: certifi==2024.8.30 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 37)) (2024.8.30)\r\n",
      "Requirement already satisfied: cffi==1.17.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 38)) (1.17.1)\r\n",
      "Requirement already satisfied: chardet==5.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 39)) (5.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer==3.4.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 40)) (3.4.0)\r\n",
      "Requirement already satisfied: click==8.1.7 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 41)) (8.1.7)\r\n",
      "Requirement already satisfied: cloudpickle==3.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 42)) (3.1.0)\r\n",
      "Requirement already satisfied: colorama==0.4.6 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 43)) (0.4.6)\r\n",
      "Requirement already satisfied: colorful==0.5.6 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 44)) (0.5.6)\r\n",
      "Requirement already satisfied: comm==0.2.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 45)) (0.2.2)\r\n",
      "Requirement already satisfied: connexion==3.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 46)) (3.1.0)\r\n",
      "Requirement already satisfied: contourpy==1.3.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 47)) (1.3.1)\r\n",
      "Requirement already satisfied: cookiecutter==2.6.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 48)) (2.6.0)\r\n",
      "Requirement already satisfied: coolname==2.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 49)) (2.2.0)\r\n",
      "Requirement already satisfied: croniter==4.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 50)) (4.0.0)\r\n",
      "Requirement already satisfied: cryptography==43.0.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 51)) (43.0.3)\r\n",
      "Requirement already satisfied: cut-cross-entropy==24.11.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 52)) (24.11.4)\r\n",
      "Requirement already satisfied: cycler==0.12.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 53)) (0.12.1)\r\n",
      "Requirement already satisfied: databricks-sdk==0.37.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 54)) (0.37.0)\r\n",
      "Requirement already satisfied: datasets==3.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 55)) (3.1.0)\r\n",
      "Requirement already satisfied: dateparser==1.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 56)) (1.2.0)\r\n",
      "Requirement already satisfied: debugpy==1.8.8 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 57)) (1.8.8)\r\n",
      "Requirement already satisfied: decorator==5.1.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 58)) (5.1.1)\r\n",
      "Requirement already satisfied: defusedxml==0.7.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 59)) (0.7.1)\r\n",
      "Requirement already satisfied: deprecated==1.2.15 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 60)) (1.2.15)\r\n",
      "Requirement already satisfied: diffusers==0.31.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 61)) (0.31.0)\r\n",
      "Requirement already satisfied: dill==0.3.8 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 62)) (0.3.8)\r\n",
      "Requirement already satisfied: distlib==0.3.9 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 63)) (0.3.9)\r\n",
      "Requirement already satisfied: distro==1.9.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 64)) (1.9.0)\r\n",
      "Requirement already satisfied: docker==7.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 65)) (7.1.0)\r\n",
      "Requirement already satisfied: docstring-parser==0.16 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 66)) (0.16)\r\n",
      "Requirement already satisfied: durationpy==0.9 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 67)) (0.9)\r\n",
      "Requirement already satisfied: dynaconf==3.2.6 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 68)) (3.2.6)\r\n",
      "Requirement already satisfied: entrypoints==0.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 69)) (0.4)\r\n",
      "Requirement already satisfied: et-xmlfile==2.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 70)) (2.0.0)\r\n",
      "Requirement already satisfied: evaluate==0.4.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 71)) (0.4.3)\r\n",
      "Requirement already satisfied: exceptiongroup==1.2.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 72)) (1.2.2)\r\n",
      "Requirement already satisfied: executing==2.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 73)) (2.1.0)\r\n",
      "Requirement already satisfied: farama-notifications==0.0.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 74)) (0.0.4)\r\n",
      "Requirement already satisfied: fastapi==0.115.5 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 75)) (0.115.5)\r\n",
      "Requirement already satisfied: fastjsonschema==2.20.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 76)) (2.20.0)\r\n",
      "Requirement already satisfied: filelock==3.16.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 77)) (3.16.1)\r\n",
      "Requirement already satisfied: fire==0.7.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 78)) (0.7.0)\r\n",
      "Requirement already satisfied: flask==3.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 79)) (3.1.0)\r\n",
      "Requirement already satisfied: flet-core==0.24.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 80)) (0.24.1)\r\n",
      "Requirement already satisfied: flet-runtime==0.24.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 81)) (0.24.1)\r\n",
      "Requirement already satisfied: flet==0.24.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 82)) (0.24.1)\r\n",
      "Requirement already satisfied: fonttools==4.55.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 83)) (4.55.0)\r\n",
      "Requirement already satisfied: fqdn==1.5.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 84)) (1.5.1)\r\n",
      "Requirement already satisfied: frozenlist==1.5.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 85)) (1.5.0)\r\n",
      "Requirement already satisfied: fsspec==2024.9.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 86)) (2024.9.0)\r\n",
      "Requirement already satisfied: future==1.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 88)) (1.0.0)\r\n",
      "Requirement already satisfied: gitdb==4.0.11 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 89)) (4.0.11)\r\n",
      "Requirement already satisfied: gitpython==3.1.43 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 90)) (3.1.43)\r\n",
      "Requirement already satisfied: google-api-core==2.23.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 91)) (2.23.0)\r\n",
      "Requirement already satisfied: google-auth==2.36.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 92)) (2.36.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos==1.66.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 93)) (1.66.0)\r\n",
      "Requirement already satisfied: graphene==3.4.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 94)) (3.4.3)\r\n",
      "Requirement already satisfied: graphql-core==3.2.5 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 95)) (3.2.5)\r\n",
      "Requirement already satisfied: graphql-relay==3.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 96)) (3.2.0)\r\n",
      "Requirement already satisfied: graphviz==0.20.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 97)) (0.20.3)\r\n",
      "Requirement already satisfied: greenlet==3.1.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 98)) (3.1.1)\r\n",
      "Requirement already satisfied: griffe==1.5.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 99)) (1.5.1)\r\n",
      "Requirement already satisfied: grpcio==1.68.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 100)) (1.68.0)\r\n",
      "Requirement already satisfied: gunicorn==23.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 101)) (23.0.0)\r\n",
      "Requirement already satisfied: gymnasium==1.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 102)) (1.0.0)\r\n",
      "Requirement already satisfied: h11==0.14.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 103)) (0.14.0)\r\n",
      "Requirement already satisfied: h2==4.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 104)) (4.1.0)\r\n",
      "Requirement already satisfied: hf-transfer==0.1.8 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 105)) (0.1.8)\r\n",
      "Requirement already satisfied: hpack==4.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 106)) (4.0.0)\r\n",
      "Requirement already satisfied: httpcore==1.0.7 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 107)) (1.0.7)\r\n",
      "Requirement already satisfied: httptools==0.6.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 108)) (0.6.4)\r\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 109)) (0.4.0)\r\n",
      "Requirement already satisfied: httpx==0.27.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 110)) (0.27.2)\r\n",
      "Requirement already satisfied: huggingface-hub==0.26.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 112)) (0.26.2)\r\n",
      "Requirement already satisfied: humanize==4.11.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 113)) (4.11.0)\r\n",
      "Requirement already satisfied: hyperframe==6.0.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 114)) (6.0.1)\r\n",
      "Requirement already satisfied: hyperopt==0.2.7 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 115)) (0.2.7)\r\n",
      "Requirement already satisfied: idna==3.10 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 116)) (3.10)\r\n",
      "Requirement already satisfied: importlib-metadata==8.5.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 117)) (8.5.0)\r\n",
      "Requirement already satisfied: importlib-resources==6.4.5 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 118)) (6.4.5)\r\n",
      "Requirement already satisfied: inflection==0.5.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 119)) (0.5.1)\r\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 120)) (6.29.5)\r\n",
      "Requirement already satisfied: ipylab==1.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 121)) (1.0.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython==8.29.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 122)) (8.29.0)\r\n",
      "Requirement already satisfied: ipywidgets==8.1.5 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 123)) (8.1.5)\r\n",
      "Requirement already satisfied: isoduration==20.11.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 124)) (20.11.0)\r\n",
      "Requirement already satisfied: isort==5.13.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 125)) (5.13.2)\r\n",
      "Requirement already satisfied: itsdangerous==2.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 126)) (2.2.0)\r\n",
      "Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 127)) (0.19.2)\r\n",
      "Requirement already satisfied: jinja2-humanize-extension==0.4.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 128)) (0.4.0)\r\n",
      "Requirement already satisfied: jinja2==3.1.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 129)) (3.1.4)\r\n",
      "Requirement already satisfied: jiter==0.7.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 130)) (0.7.1)\r\n",
      "Requirement already satisfied: joblib==1.4.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 131)) (1.4.2)\r\n",
      "Requirement already satisfied: json5==0.9.28 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 132)) (0.9.28)\r\n",
      "Requirement already satisfied: jsonpatch==1.33 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 133)) (1.33)\r\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 134)) (3.0.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications==2024.10.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 135)) (2024.10.1)\r\n",
      "Requirement already satisfied: jsonschema==4.23.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 136)) (4.23.0)\r\n",
      "Requirement already satisfied: jupyter-client==8.6.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 138)) (8.6.3)\r\n",
      "Requirement already satisfied: jupyter-console==6.6.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 139)) (6.6.3)\r\n",
      "Requirement already satisfied: jupyter-core==5.7.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 140)) (5.7.2)\r\n",
      "Requirement already satisfied: jupyter-events==0.10.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 141)) (0.10.0)\r\n",
      "Requirement already satisfied: jupyter-lsp==2.2.5 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 142)) (2.2.5)\r\n",
      "Requirement already satisfied: jupyter-server-terminals==0.5.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 143)) (0.5.3)\r\n",
      "Requirement already satisfied: jupyter-server==2.14.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 144)) (2.14.2)\r\n",
      "Requirement already satisfied: jupyter==1.1.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 145)) (1.1.1)\r\n",
      "Requirement already satisfied: jupyterlab-pygments==0.3.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 146)) (0.3.0)\r\n",
      "Requirement already satisfied: jupyterlab-server==2.27.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 147)) (2.27.3)\r\n",
      "Requirement already satisfied: jupyterlab-widgets==3.0.13 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 148)) (3.0.13)\r\n",
      "Requirement already satisfied: jupyterlab==4.2.6 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 149)) (4.2.6)\r\n",
      "Requirement already satisfied: kedro-datasets==5.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 150)) (5.1.0)\r\n",
      "Requirement already satisfied: kedro-mlflow==0.13.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 152)) (0.13.3)\r\n",
      "Requirement already satisfied: kedro-telemetry==0.6.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 153)) (0.6.1)\r\n",
      "Requirement already satisfied: kedro==0.19.9 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 154)) (0.19.9)\r\n",
      "Requirement already satisfied: kiwisolver==1.4.7 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 156)) (1.4.7)\r\n",
      "Requirement already satisfied: kubernetes==31.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 157)) (31.0.0)\r\n",
      "Requirement already satisfied: lazy-loader==0.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 158)) (0.4)\r\n",
      "Requirement already satisfied: linkify-it-py==2.0.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 159)) (2.0.3)\r\n",
      "Requirement already satisfied: llama-models==0.0.55 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 160)) (0.0.55)\r\n",
      "Requirement already satisfied: llama-stack-client==0.0.55 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 161)) (0.0.55)\r\n",
      "Requirement already satisfied: llama-stack==0.0.55 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 162)) (0.0.55)\r\n",
      "Requirement already satisfied: lxml==5.3.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 163)) (5.3.0)\r\n",
      "Requirement already satisfied: mako==1.3.6 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 164)) (1.3.6)\r\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 165)) (3.0.0)\r\n",
      "Requirement already satisfied: markdown==3.7 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 167)) (3.7)\r\n",
      "Requirement already satisfied: markupsafe==3.0.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 168)) (3.0.2)\r\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 169)) (0.1.7)\r\n",
      "Requirement already satisfied: matplotlib==3.9.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 170)) (3.9.2)\r\n",
      "Requirement already satisfied: mcp==1.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 171)) (1.0.0)\r\n",
      "Requirement already satisfied: mdit-py-plugins==0.4.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 172)) (0.4.2)\r\n",
      "Requirement already satisfied: mdurl==0.1.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 173)) (0.1.2)\r\n",
      "Requirement already satisfied: memray==1.14.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 174)) (1.14.0)\r\n",
      "Requirement already satisfied: mistune==3.0.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 175)) (3.0.2)\r\n",
      "Requirement already satisfied: mlflow-skinny==2.17.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 176)) (2.17.2)\r\n",
      "Requirement already satisfied: mlflow==2.17.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 177)) (2.17.2)\r\n",
      "Requirement already satisfied: more-itertools==10.5.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 178)) (10.5.0)\r\n",
      "Requirement already satisfied: mpmath==1.3.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 179)) (1.3.0)\r\n",
      "Requirement already satisfied: msgpack==1.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 180)) (1.1.0)\r\n",
      "Requirement already satisfied: multidict==6.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 181)) (6.1.0)\r\n",
      "Requirement already satisfied: multiprocess==0.70.16 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 182)) (0.70.16)\r\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 183)) (1.0.0)\r\n",
      "Requirement already satisfied: nbclient==0.10.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 184)) (0.10.0)\r\n",
      "Requirement already satisfied: nbconvert==7.16.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 185)) (7.16.4)\r\n",
      "Requirement already satisfied: nbformat==5.10.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 186)) (5.10.4)\r\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 187)) (1.6.0)\r\n",
      "Requirement already satisfied: networkx==3.4.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 188)) (3.4.2)\r\n",
      "Requirement already satisfied: nltk==3.9.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 189)) (3.9.1)\r\n",
      "Requirement already satisfied: notebook-shim==0.2.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 190)) (0.2.4)\r\n",
      "Requirement already satisfied: notebook==7.2.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 191)) (7.2.2)\r\n",
      "Requirement already satisfied: numpy==1.26.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 192)) (1.26.4)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 193)) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 194)) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 195)) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 196)) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 197)) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 198)) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 199)) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 200)) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 201)) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 202)) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 203)) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 204)) (12.4.127)\r\n",
      "Requirement already satisfied: oauthlib==3.2.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 205)) (3.2.2)\r\n",
      "Requirement already satisfied: omegaconf==2.3.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 206)) (2.3.0)\r\n",
      "Requirement already satisfied: openai==1.54.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 207)) (1.54.4)\r\n",
      "Requirement already satisfied: opencensus-context==0.1.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 208)) (0.1.3)\r\n",
      "Requirement already satisfied: opencensus==0.11.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 209)) (0.11.4)\r\n",
      "Requirement already satisfied: openpyxl==3.1.5 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 210)) (3.1.5)\r\n",
      "Requirement already satisfied: opentelemetry-api==1.28.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 211)) (1.28.1)\r\n",
      "Requirement already satisfied: opentelemetry-sdk==1.28.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 212)) (1.28.1)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 213)) (0.49b1)\r\n",
      "Requirement already satisfied: orjson==3.10.11 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 214)) (3.10.11)\r\n",
      "Requirement already satisfied: overrides==7.7.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 215)) (7.7.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging==23.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 216)) (23.2)\r\n",
      "Requirement already satisfied: pandas==2.2.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 217)) (2.2.3)\r\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 218)) (1.5.1)\r\n",
      "Requirement already satisfied: papermill==2.6.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 219)) (2.6.0)\r\n",
      "Requirement already satisfied: parse==1.20.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 220)) (1.20.2)\r\n",
      "Requirement already satisfied: parso==0.8.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 221)) (0.8.4)\r\n",
      "Requirement already satisfied: pathspec==0.12.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 222)) (0.12.1)\r\n",
      "Requirement already satisfied: peft==0.13.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 223)) (0.13.2)\r\n",
      "Requirement already satisfied: pendulum==3.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 224)) (3.0.0)\r\n",
      "Requirement already satisfied: pettingzoo==1.24.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 225)) (1.24.3)\r\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 226)) (4.9.0)\r\n",
      "Requirement already satisfied: pillow==11.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 227)) (11.0.0)\r\n",
      "Requirement already satisfied: platformdirs==4.3.6 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 228)) (4.3.6)\r\n",
      "Requirement already satisfied: pluggy==1.5.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 229)) (1.5.0)\r\n",
      "Requirement already satisfied: pre-commit-hooks==5.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 230)) (5.0.0)\r\n",
      "Requirement already satisfied: prefect-docker==0.6.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 231)) (0.6.2)\r\n",
      "Requirement already satisfied: prefect==3.1.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 232)) (3.1.2)\r\n",
      "Requirement already satisfied: prettytable==3.12.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 233)) (3.12.0)\r\n",
      "Requirement already satisfied: prometheus-client==0.21.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 234)) (0.21.0)\r\n",
      "Requirement already satisfied: prompt-toolkit==3.0.48 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 235)) (3.0.48)\r\n",
      "Requirement already satisfied: propcache==0.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 236)) (0.2.0)\r\n",
      "Requirement already satisfied: proto-plus==1.25.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 237)) (1.25.0)\r\n",
      "Requirement already satisfied: protobuf==3.20.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 238)) (3.20.3)\r\n",
      "Requirement already satisfied: psutil==6.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 239)) (6.1.0)\r\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 240)) (0.7.0)\r\n",
      "Requirement already satisfied: pulp==2.9.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 241)) (2.9.0)\r\n",
      "Requirement already satisfied: pure-eval==0.2.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 242)) (0.2.3)\r\n",
      "Requirement already satisfied: py-spy==0.4.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 243)) (0.4.0)\r\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 244)) (0.10.9.7)\r\n",
      "Requirement already satisfied: pyaml==24.9.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 245)) (24.9.0)\r\n",
      "Requirement already satisfied: pyarrow==17.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 246)) (17.0.0)\r\n",
      "Requirement already satisfied: pyasn1-modules==0.4.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 247)) (0.4.1)\r\n",
      "Requirement already satisfied: pyasn1==0.6.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 248)) (0.6.1)\r\n",
      "Requirement already satisfied: pycparser==2.22 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 249)) (2.22)\r\n",
      "Requirement already satisfied: pycryptodomex==3.21.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 250)) (3.21.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 251)) (2.27.0)\r\n",
      "Requirement already satisfied: pydantic-extra-types==2.10.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 252)) (2.10.0)\r\n",
      "Requirement already satisfied: pydantic-settings==2.6.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 253)) (2.6.1)\r\n",
      "Requirement already satisfied: pydantic==2.10.0b2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 254)) (2.10.0b2)\r\n",
      "Requirement already satisfied: pygments==2.18.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 255)) (2.18.0)\r\n",
      "Requirement already satisfied: pynvml==11.5.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 256)) (11.5.3)\r\n",
      "Requirement already satisfied: pyparsing==3.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 257)) (3.2.0)\r\n",
      "Requirement already satisfied: pyphen==0.17.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 258)) (0.17.0)\r\n",
      "Requirement already satisfied: pypng==0.20220715.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 259)) (0.20220715.0)\r\n",
      "Requirement already satisfied: pyproject-hooks==1.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 260)) (1.2.0)\r\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 261)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 262)) (1.0.1)\r\n",
      "Requirement already satisfied: python-json-logger==2.0.7 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 263)) (2.0.7)\r\n",
      "Requirement already satisfied: python-multipart==0.0.17 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 264)) (0.0.17)\r\n",
      "Requirement already satisfied: python-slugify==8.0.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 265)) (8.0.4)\r\n",
      "Requirement already satisfied: pytoolconfig==1.3.1 in ./.venv/lib/python3.10/site-packages (from pytoolconfig[global]==1.3.1->-r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 266)) (1.3.1)\r\n",
      "Requirement already satisfied: pytz==2024.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 267)) (2024.2)\r\n",
      "Requirement already satisfied: pyyaml==6.0.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 270)) (6.0.2)\r\n",
      "Requirement already satisfied: pyzmq==26.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 271)) (26.2.0)\r\n",
      "Requirement already satisfied: qrcode==7.4.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 272)) (7.4.2)\r\n",
      "Requirement already satisfied: ray==2.39.0 in ./.venv/lib/python3.10/site-packages (from ray[serve,tune]==2.39.0->-r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 273)) (2.39.0)\r\n",
      "Requirement already satisfied: readchar==4.2.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 274)) (4.2.1)\r\n",
      "Requirement already satisfied: referencing==0.35.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 275)) (0.35.1)\r\n",
      "Requirement already satisfied: regex==2024.11.6 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 276)) (2024.11.6)\r\n",
      "Requirement already satisfied: repath==0.9.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 277)) (0.9.0)\r\n",
      "Requirement already satisfied: requests-oauthlib==2.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 278)) (2.0.0)\r\n",
      "Requirement already satisfied: requests==2.32.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 279)) (2.32.3)\r\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 280)) (0.1.4)\r\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 281)) (0.1.1)\r\n",
      "Requirement already satisfied: rich==13.9.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 282)) (13.9.4)\r\n",
      "Requirement already satisfied: rope==1.13.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 283)) (1.13.0)\r\n",
      "Requirement already satisfied: rouge-score==0.1.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 284)) (0.1.2)\r\n",
      "Requirement already satisfied: rpds-py==0.21.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 285)) (0.21.0)\r\n",
      "Requirement already satisfied: rsa==4.9 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 286)) (4.9)\r\n",
      "Requirement already satisfied: ruamel-yaml-clib==0.2.12 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 287)) (0.2.12)\r\n",
      "Requirement already satisfied: ruamel-yaml==0.18.6 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 288)) (0.18.6)\r\n",
      "Requirement already satisfied: safetensors==0.4.5 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 289)) (0.4.5)\r\n",
      "Requirement already satisfied: scikit-learn==1.5.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 290)) (1.5.2)\r\n",
      "Requirement already satisfied: scipy==1.14.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 291)) (1.14.1)\r\n",
      "Requirement already satisfied: send2trash==1.8.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 292)) (1.8.3)\r\n",
      "Requirement already satisfied: sentencepiece==0.2.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 293)) (0.2.0)\r\n",
      "Requirement already satisfied: setuptools==75.5.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 294)) (75.5.0)\r\n",
      "Requirement already satisfied: shellingham==1.5.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 295)) (1.5.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shtab==1.7.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 296)) (1.7.1)\r\n",
      "Requirement already satisfied: six==1.16.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 297)) (1.16.0)\r\n",
      "Requirement already satisfied: skypilot==0.7.0 in ./.venv/lib/python3.10/site-packages (from skypilot[kubernetes]==0.7.0->-r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 298)) (0.7.0)\r\n",
      "Requirement already satisfied: smart-open==7.0.5 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 299)) (7.0.5)\r\n",
      "Requirement already satisfied: smmap==5.0.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 300)) (5.0.1)\r\n",
      "Requirement already satisfied: sniffio==1.3.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 301)) (1.3.1)\r\n",
      "Requirement already satisfied: soupsieve==2.6 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 302)) (2.6)\r\n",
      "Requirement already satisfied: sqlalchemy==2.0.36 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 303)) (2.0.36)\r\n",
      "Requirement already satisfied: sqlparse==0.5.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 305)) (0.5.2)\r\n",
      "Requirement already satisfied: sse-starlette==2.1.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 306)) (2.1.3)\r\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 307)) (0.6.3)\r\n",
      "Requirement already satisfied: starlette==0.41.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 308)) (0.41.2)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 309)) (1.13.1)\r\n",
      "Requirement already satisfied: tabulate==0.9.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 310)) (0.9.0)\r\n",
      "Requirement already satisfied: tenacity==9.0.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 311)) (9.0.0)\r\n",
      "Requirement already satisfied: tensorboardx==2.6.2.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 312)) (2.6.2.2)\r\n",
      "Requirement already satisfied: termcolor==2.5.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 313)) (2.5.0)\r\n",
      "Requirement already satisfied: terminado==0.18.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 314)) (0.18.1)\r\n",
      "Requirement already satisfied: text-unidecode==1.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 315)) (1.3)\r\n",
      "Requirement already satisfied: textstat==0.7.4 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 316)) (0.7.4)\r\n",
      "Requirement already satisfied: textual==0.87.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 317)) (0.87.1)\r\n",
      "Requirement already satisfied: threadpoolctl==3.5.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 318)) (3.5.0)\r\n",
      "Requirement already satisfied: tiktoken==0.8.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 319)) (0.8.0)\r\n",
      "Requirement already satisfied: tinycss2==1.4.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 320)) (1.4.0)\r\n",
      "Requirement already satisfied: tokenize-rt==6.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 321)) (6.1.0)\r\n",
      "Requirement already satisfied: tokenizers==0.20.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 322)) (0.20.3)\r\n",
      "Requirement already satisfied: toml-sort==0.23.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 323)) (0.23.1)\r\n",
      "Requirement already satisfied: toml==0.10.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 324)) (0.10.2)\r\n",
      "Requirement already satisfied: tomli==2.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 325)) (2.1.0)\r\n",
      "Requirement already satisfied: tomlkit==0.13.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 326)) (0.13.2)\r\n",
      "Requirement already satisfied: torch==2.5.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 327)) (2.5.1)\r\n",
      "Requirement already satisfied: torchvision==0.20.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 328)) (0.20.1)\r\n",
      "Requirement already satisfied: tornado==6.4.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 329)) (6.4.1)\r\n",
      "Requirement already satisfied: tqdm==4.67.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 330)) (4.67.0)\r\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 331)) (5.14.3)\r\n",
      "Requirement already satisfied: transformers==4.46.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 332)) (4.46.2)\r\n",
      "Requirement already satisfied: triton==3.1.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 333)) (3.1.0)\r\n",
      "Requirement already satisfied: trl==0.12.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 334)) (0.12.1)\r\n",
      "Requirement already satisfied: typer==0.13.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 335)) (0.13.0)\r\n",
      "Requirement already satisfied: types-python-dateutil==2.9.0.20241003 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 336)) (2.9.0.20241003)\r\n",
      "Requirement already satisfied: typing-extensions==4.12.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 337)) (4.12.2)\r\n",
      "Requirement already satisfied: tyro==0.8.14 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 338)) (0.8.14)\r\n",
      "Requirement already satisfied: tzdata==2024.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 339)) (2024.2)\r\n",
      "Requirement already satisfied: tzlocal==5.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 340)) (5.2)\r\n",
      "Requirement already satisfied: uc-micro-py==1.0.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 341)) (1.0.3)\r\n",
      "Requirement already satisfied: ujson==5.10.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 342)) (5.10.0)\r\n",
      "Requirement already satisfied: unsloth-zoo==2024.11.8 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 343)) (2024.11.8)\r\n",
      "Requirement already satisfied: unsloth==2024.11.5 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 344)) (2024.11.5)\r\n",
      "Requirement already satisfied: uri-template==1.3.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 345)) (1.3.0)\r\n",
      "Requirement already satisfied: urllib3==2.2.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 346)) (2.2.3)\r\n",
      "Requirement already satisfied: uvicorn==0.32.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 347)) (0.32.0)\r\n",
      "Requirement already satisfied: uvloop==0.21.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 349)) (0.21.0)\r\n",
      "Requirement already satisfied: virtualenv==20.28.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 350)) (20.28.0)\r\n",
      "Requirement already satisfied: watchdog==4.0.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 352)) (4.0.2)\r\n",
      "Requirement already satisfied: watchfiles==0.24.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 353)) (0.24.0)\r\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 354)) (0.2.13)\r\n",
      "Requirement already satisfied: webcolors==24.11.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 355)) (24.11.1)\r\n",
      "Requirement already satisfied: webencodings==0.5.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 356)) (0.5.1)\r\n",
      "Requirement already satisfied: websocket-client==1.8.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 357)) (1.8.0)\r\n",
      "Requirement already satisfied: websockets==13.1 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 358)) (13.1)\r\n",
      "Requirement already satisfied: werkzeug==3.1.3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 359)) (3.1.3)\r\n",
      "Requirement already satisfied: wheel==0.45.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 360)) (0.45.0)\r\n",
      "Requirement already satisfied: widgetsnbextension==4.0.13 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 361)) (4.0.13)\r\n",
      "Requirement already satisfied: wrapt==1.16.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 362)) (1.16.0)\r\n",
      "Requirement already satisfied: xformers==0.0.28.post3 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 363)) (0.0.28.post3)\r\n",
      "Requirement already satisfied: xxhash==3.5.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 364)) (3.5.0)\r\n",
      "Requirement already satisfied: yarl==1.17.2 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 365)) (1.17.2)\r\n",
      "Requirement already satisfied: zipp==3.21.0 in ./.venv/lib/python3.10/site-packages (from -r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 366)) (3.21.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: time-machine>=2.6.0 in ./.venv/lib/python3.10/site-packages (from pendulum==3.0.0->-r /home/mjschock/Projects/training-tinyllama-for-tool-calling/requirements.txt (line 224)) (2.16.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Current working directory: /home/mjschock/Projects/training-tinyllama-for-tool-calling\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def setup_environment():\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    if cwd == '/content':\n",
    "        print(\"Running on Google Colab\")\n",
    "\n",
    "        %pip install unsloth\n",
    "        %pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n",
    "\n",
    "    elif cwd == '/kaggle/working':\n",
    "        print(\"Running on Kaggle\")\n",
    "\n",
    "        %pip install pip3-autoremove\n",
    "        %pip-autoremove torch torchvision torchaudio -y\n",
    "        %pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n",
    "        %pip install unsloth\n",
    "\n",
    "    else:\n",
    "        print(\"Running in local environment\")\n",
    "\n",
    "        req_file = find_requirements_txt()\n",
    "\n",
    "        if req_file:\n",
    "            print(f\"Found requirements.txt at: {req_file}\")\n",
    "\n",
    "            cwd = os.path.dirname(req_file)\n",
    "\n",
    "            %pip install -r {req_file}\n",
    "\n",
    "        else:\n",
    "            print(\"requirements.txt not found. Skipping installation.\")\n",
    "\n",
    "    print(f\"Current working directory: {cwd}\")\n",
    "\n",
    "    return cwd\n",
    "\n",
    "def find_requirements_txt():\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    while cwd != '/':\n",
    "        req_file = os.path.join(cwd, 'requirements.txt')\n",
    "\n",
    "        if os.path.exists(req_file):\n",
    "            return req_file\n",
    "\n",
    "        cwd = os.path.dirname(cwd)\n",
    "\n",
    "    return None\n",
    "\n",
    "cwd = setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce6c208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:02.155771Z",
     "iopub.status.busy": "2024-11-29T18:38:02.155512Z",
     "iopub.status.idle": "2024-11-29T18:38:10.109330Z",
     "shell.execute_reply": "2024-11-29T18:38:10.108342Z"
    },
    "id": "QmUBVEnvCDJv",
    "outputId": "5eff0d61-05b4-471c-eea2-c2e84a915109",
    "papermill": {
     "duration": 8.006457,
     "end_time": "2024-11-29T18:38:10.111813",
     "exception": false,
     "start_time": "2024-11-29T18:38:02.105356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Dict, List\n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import mlflow\n",
    "from mlflow.types.llm import (\n",
    "    ChatChoice,\n",
    "    ChatMessage,\n",
    "    ChatResponse,\n",
    "    FunctionToolCallArguments,\n",
    "    ToolCall,\n",
    ")\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from unsloth.chat_templates import get_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcef9ace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:10.201685Z",
     "iopub.status.busy": "2024-11-29T18:38:10.200197Z",
     "iopub.status.idle": "2024-11-29T18:38:10.284502Z",
     "shell.execute_reply": "2024-11-29T18:38:10.283587Z"
    },
    "papermill": {
     "duration": 0.124724,
     "end_time": "2024-11-29T18:38:10.285903",
     "exception": false,
     "start_time": "2024-11-29T18:38:10.161179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow_run started: dbb314a0b654499bbaefe1897a2e41dc\n",
      "mlflow_run.to_dictionary():\n",
      "{'data': {'metrics': {},\n",
      "          'params': {},\n",
      "          'tags': {'mlflow.runName': 'shivering-pug-339',\n",
      "                   'mlflow.source.name': '/home/mjschock/Projects/training-tinyllama-for-tool-calling/.venv/lib/python3.10/site-packages/ipykernel_launcher.py',\n",
      "                   'mlflow.source.type': 'LOCAL',\n",
      "                   'mlflow.user': 'mjschock'}},\n",
      " 'info': {'artifact_uri': 'file:///home/mjschock/Projects/training-tinyllama-for-tool-calling/mlruns/341257326214881697/dbb314a0b654499bbaefe1897a2e41dc/artifacts',\n",
      "          'end_time': None,\n",
      "          'experiment_id': '341257326214881697',\n",
      "          'lifecycle_stage': 'active',\n",
      "          'run_id': 'dbb314a0b654499bbaefe1897a2e41dc',\n",
      "          'run_name': 'shivering-pug-339',\n",
      "          'run_uuid': 'dbb314a0b654499bbaefe1897a2e41dc',\n",
      "          'start_time': 1732905490273,\n",
      "          'status': 'RUNNING',\n",
      "          'user_id': 'mjschock'}}\n",
      "user_id: mjschock\n"
     ]
    }
   ],
   "source": [
    "mlflow_experiment_name = \"Training TinyLlama for Tool-calling\"\n",
    "# mlflow_tracking_uri = f\"file://{project_root}/mlruns\"\n",
    "mlflow_tracking_uri = f\"file://{cwd}/mlruns\"\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "\n",
    "assert mlflow.get_tracking_uri() == mlflow_tracking_uri, f\"{mlflow.get_tracking_uri()} != {mlflow_tracking_uri}\"\n",
    "\n",
    "mlflow_experiment = mlflow.set_experiment(mlflow_experiment_name)\n",
    "\n",
    "if mlflow.active_run():\n",
    "    mlflow_run = mlflow.active_run()\n",
    "\n",
    "    print(f\"mlflow_run already exists: {mlflow_run.info.run_id}\")\n",
    "\n",
    "else:\n",
    "    mlflow_run = mlflow.start_run(\n",
    "        experiment_id=mlflow_experiment.experiment_id,\n",
    "    )\n",
    "\n",
    "    print(f\"mlflow_run started: {mlflow_run.info.run_id}\")\n",
    "\n",
    "assert mlflow_run.info.experiment_id == mlflow_experiment.experiment_id, f\"{mlflow_run.info.experiment_id} != {mlflow_experiment.experiment_id}\"\n",
    "\n",
    "print('mlflow_run.to_dictionary():')\n",
    "pprint(mlflow_run.to_dictionary())\n",
    "\n",
    "user_id = mlflow_run.info.user_id\n",
    "print('user_id:', user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91e5618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:10.366280Z",
     "iopub.status.busy": "2024-11-29T18:38:10.364952Z",
     "iopub.status.idle": "2024-11-29T18:38:16.211121Z",
     "shell.execute_reply": "2024-11-29T18:38:16.210020Z"
    },
    "papermill": {
     "duration": 5.895265,
     "end_time": "2024-11-29T18:38:16.212829",
     "exception": false,
     "start_time": "2024-11-29T18:38:10.317564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.5: Fast Llama patching. Transformers = 4.46.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce GTX 1050 Ti. Max memory: 3.94 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 6.1. CUDA Toolkit = 12.4.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: unsloth/tinyllama-chat-bnb-4bit can only handle sequence lengths of at most 2048.\n",
      "But with kaiokendev's RoPE scaling of 2.0, it can be magically be extended to 4096!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "max_seq_length = 4096\n",
    "pretrained_model_name = \"TinyLlama-1.1B-Chat-v1.0\"\n",
    "pretrained_model_namespace = \"TinyLlama\"\n",
    "# model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "# model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "pretrained_model_name_or_path = f\"{pretrained_model_namespace}/{pretrained_model_name}\"\n",
    "\n",
    "if not os.path.exists(os.path.join(cwd, f\"data/06_models/{pretrained_model_namespace}/{pretrained_model_name}\")):\n",
    "    model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path)\n",
    "\n",
    "    model.save_pretrained(os.path.join(cwd, f\"data/06_models/{pretrained_model_namespace}/{pretrained_model_name}\"))\n",
    "    tokenizer.save_pretrained(os.path.join(cwd, f\"data/06_models/{pretrained_model_namespace}/{pretrained_model_name}\"))\n",
    "\n",
    "    del model\n",
    "    del tokenizer\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    max_seq_length=max_seq_length,\n",
    "    # model_name=model_name,\n",
    "    model_name=pretrained_model_name_or_path,\n",
    ")\n",
    "\n",
    "# Save a tokenizer without padding because it is only needed for training\n",
    "# tokenizer_no_pad = AutoTokenizer.from_pretrained(model_name, add_bos_token=True) # https://mlflow.org/docs/latest/llms/transformers/tutorials/fine-tuning/transformers-peft.html#Save-the-PEFT-Model-to-MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "248f8dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:16.286843Z",
     "iopub.status.busy": "2024-11-29T18:38:16.286326Z",
     "iopub.status.idle": "2024-11-29T18:38:16.293104Z",
     "shell.execute_reply": "2024-11-29T18:38:16.292049Z"
    },
    "papermill": {
     "duration": 0.045435,
     "end_time": "2024-11-29T18:38:16.294439",
     "exception": false,
     "start_time": "2024-11-29T18:38:16.249004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pad_token: <unk>\n",
      "tokenizer.padding_side: left\n"
     ]
    }
   ],
   "source": [
    "print('tokenizer.pad_token:', tokenizer.pad_token)\n",
    "print('tokenizer.padding_side:', tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd046e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:16.354780Z",
     "iopub.status.busy": "2024-11-29T18:38:16.354339Z",
     "iopub.status.idle": "2024-11-29T18:38:16.363848Z",
     "shell.execute_reply": "2024-11-29T18:38:16.362775Z"
    },
    "papermill": {
     "duration": 0.043035,
     "end_time": "2024-11-29T18:38:16.366186",
     "exception": false,
     "start_time": "2024-11-29T18:38:16.323151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_MESSAGE = {\n",
    "    \"content\": \"You are an AI agent acting as a human assistant.\",\n",
    "    \"role\": \"system\"\n",
    "}\n",
    "\n",
    "tools_template = \"\"\"\n",
    "{\n",
    "  \"tools\": [\n",
    "  {% for tool in tools %}\n",
    "    {\n",
    "      \"function\": {\n",
    "        \"description\": \"{{ tool.function.description }}\",\n",
    "        \"name\": \"{{ tool.function.name }}\",\n",
    "        \"parameters\": {{ tool.function.parameters | tojson }}\n",
    "      },\n",
    "      \"type\": \"{{ tool.type }}\"\n",
    "    }{% if not loop.last %},{% endif %}\\n\n",
    "  {% endfor %}\n",
    "  ]\n",
    "}\n",
    "\n",
    "If you would like to suggest one or more tool calls, please respond in the following format:\n",
    "{\n",
    "  \"finish_reason\": \"tool_calls\",\n",
    "  \"tool_calls\": [\n",
    "    {\n",
    "      \"arguments\": \"{\\\\\"parameter_name\\\\\": \\\\\"parameter_value\\\\\"}\",\n",
    "      \"id\": \"call_id\",\n",
    "      \"name\": \"tool_name\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "tool_calls_template = \"\"\"\n",
    "{\n",
    "  \"finish_reason\": \"tool_calls\",\n",
    "  \"tool_calls\": [\n",
    "  {% for tool_call in message.tool_calls %}\n",
    "    {\n",
    "      \"arguments\": {{ tool_call.function.arguments | tojson }},\n",
    "      \"id\": \"{{ tool_call.id }}\",\n",
    "      \"name\": \"{{ tool_call.function.name }}\"\n",
    "    }{% if not loop.last %},{% endif %}\\n\n",
    "  {% endfor %}\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "tool_response_template = \"\"\"\n",
    "{\n",
    "  \"content\": {{ message.content | tojson }},\n",
    "  \"name\": \"{{ message.name }}\",\n",
    "  \"tool_call_id\": \"{{ message.tool_call_id }}\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# if model_name == \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\":\n",
    "if pretrained_model_name == \"TinyLlama-1.1B-Chat-v1.0\":\n",
    "  start_header_id = \"<|\"\n",
    "  end_header_id = \"|>\"\n",
    "\n",
    "else:\n",
    "  start_header_id = \"<|start_header_id|>\"\n",
    "  end_header_id = \"<|end_header_id|>\"\n",
    "\n",
    "role_header_template = start_header_id + \"{{ message.role }}\" + end_header_id + \"{{ '\\n' }}\"\n",
    "assistant_generation_role_header_template = start_header_id + \"assistant\" + end_header_id + \"{{ '\\n' }}\"\n",
    "\n",
    "# Influenced by:\n",
    "# https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models\n",
    "# https://docs.anthropic.com/en/docs/build-with-claude/tool-use\n",
    "# https://github.com/abetlen/llama-cpp-python/blob/7c4aead82d349469bbbe7d8c0f4678825873c039/llama_cpp/llama_chat_format.py#L3387\n",
    "# https://github.com/Mozilla-Ocho/llamafile/blob/66a84d8aea2990895fc4f64786406fea64e79197/llama.cpp/server/server.cpp#L480 (need <|im_start|> b/c Mozilla)\n",
    "# https://github.com/openai/openai-python/blob/120d225b91a8453e15240a49fb1c6794d8119326/chatml.md\n",
    "# https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html#prompt\n",
    "# https://huggingface.co/blog/unified-tool-use\n",
    "chat_template = (\n",
    "    # Configuration and defaults\n",
    "    \"{%- set config = namespace(has_system_message=false, has_tools=false) -%}\"\n",
    "    \"{%- set system_messages = messages | selectattr('role', 'equalto', 'system') | list -%}\"\n",
    "    \"{%- set config.has_system_message = system_messages | length > 0 -%}\"\n",
    "    \"{%- set config.has_tools = tools is defined and tools | length > 0 -%}\"\n",
    "\n",
    "    # Ensure system message exists\n",
    "    \"{%- if not config.has_system_message -%}\"\n",
    "    f'{{%- set messages = [{{ \"content\": \"{DEFAULT_SYSTEM_MESSAGE[\"content\"]}\", \"role\": \"{DEFAULT_SYSTEM_MESSAGE[\"role\"]}\" }}] + messages -%}}'\n",
    "    \"{%- endif -%}\"\n",
    "\n",
    "    # Process messages\n",
    "    \"{%- for message in messages -%}\"\n",
    "    # \"<|{{ message.role }}|>{{ '\\n' }}\" # \"<|start_header_id|>{{ message.role }}<|end_header_id|>{{ '\\n' }}\"\n",
    "    # f\"{start_header_id}{{ message.role }}{end_header_id}{{ '\\n' }}\"\n",
    "    # start_header_id + \"{{ message.role }}\" + end_header_id + \"{{ '\\n' }}\"\n",
    "    # TODO: add bos_token if first message?\n",
    "    \"{% if loop.first %}{{ bos_token }}{% endif %}\"f\"{role_header_template}\"\n",
    "\n",
    "    # System message handling\n",
    "    \"{%- if message.role == 'system' -%}\"\n",
    "    \"{{ message.content }}\"\n",
    "    \"{%- if config.has_tools -%}\"\n",
    "    \"{{ '\\n\\n' }}You are aware of the following tools in your environment:\"\n",
    "    f\"{tools_template}\"\n",
    "    \"{%- endif -%}\"\n",
    "    \"{{ eos_token }}{{ '\\n' }}\" # <|eot_id|>\n",
    "    \"{%- endif -%}\"\n",
    "\n",
    "    # User message handling\n",
    "    \"{%- if message.role == 'user' -%}\"\n",
    "    \"{{ message.content }}{{ eos_token }}{{ '\\n' }}\"\n",
    "    \"{%- endif -%}\"\n",
    "\n",
    "    # Assistant message handling\n",
    "    \"{%- if message.role == 'assistant' -%}\"\n",
    "    \"{% generation %}\"\n",
    "    \"{%- if message.tool_calls | default(false) -%}\"\n",
    "    f\"{tool_calls_template}\"\n",
    "    \"{%- else -%}\"\n",
    "    \"{{ message.content }}\"\n",
    "    \"{%- endif -%}\"\n",
    "    \"{% endgeneration %}\"\n",
    "    \"{{ eos_token }}{{ '\\n' }}\"\n",
    "    \"{%- endif -%}\"\n",
    "\n",
    "    # Tool message handling\n",
    "    \"{%- if message.role == 'tool' -%}\"\n",
    "    f\"{tool_response_template}\"\n",
    "    \"{{ eos_token }}{{ '\\n' }}\"\n",
    "    \"{%- endif -%}\"\n",
    "    \"{%- endfor -%}\"\n",
    "\n",
    "    # Generation prompt\n",
    "    \"{%- if add_generation_prompt -%}\"\n",
    "    # \"<|assistant|>{{ '\\n' }}\" # <|start_header_id|>assistant<|end_header_id|>\n",
    "    f\"{assistant_generation_role_header_template}\"\n",
    "    \"{%- endif -%}\"\n",
    ")\n",
    "\n",
    "# tokenizer = get_chat_template(\n",
    "#     tokenizer,\n",
    "#     chat_template=(\n",
    "#         chat_template,\n",
    "#         \"eos_token\"\n",
    "#     ),\n",
    "#     map_eos_token=True,\n",
    "# )\n",
    "\n",
    "tokenizer.chat_template = chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18740d97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:16.444592Z",
     "iopub.status.busy": "2024-11-29T18:38:16.444314Z",
     "iopub.status.idle": "2024-11-29T18:38:16.452600Z",
     "shell.execute_reply": "2024-11-29T18:38:16.451422Z"
    },
    "papermill": {
     "duration": 0.053728,
     "end_time": "2024-11-29T18:38:16.455208",
     "exception": false,
     "start_time": "2024-11-29T18:38:16.401480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert model.config.bos_token_id == tokenizer.bos_token_id, f\"{model.config.bos_token_id} != {tokenizer.bos_token_id}\"\n",
    "\n",
    "try:\n",
    "    assert model.config.eos_token_id == tokenizer.eos_token_id, f\"{model.config.eos_token_id} != {tokenizer.eos_token_id}\"\n",
    "\n",
    "except AssertionError as e:\n",
    "    print(e)\n",
    "    model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "assert model.config.pad_token_id == tokenizer.pad_token_id, f\"{model.config.pad_token_id} != {tokenizer.pad_token_id}\"\n",
    "\n",
    "assert model.generation_config.bos_token_id == tokenizer.bos_token_id, f\"{model.generation_config.bos_token_id} != {tokenizer.bos_token_id}\"\n",
    "\n",
    "try:\n",
    "    assert model.generation_config.eos_token_id == tokenizer.eos_token_id, f\"{model.generation_config.eos_token_id} != {tokenizer.eos_token_id}\"\n",
    "\n",
    "except AssertionError as e:\n",
    "    print(e)\n",
    "    model.generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "assert model.generation_config.pad_token_id == tokenizer.pad_token_id, f\"{model.generation_config.pad_token_id} != {tokenizer.pad_token_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2279008",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:16.524621Z",
     "iopub.status.busy": "2024-11-29T18:38:16.524339Z",
     "iopub.status.idle": "2024-11-29T18:38:16.528953Z",
     "shell.execute_reply": "2024-11-29T18:38:16.528122Z"
    },
    "papermill": {
     "duration": 0.040965,
     "end_time": "2024-11-29T18:38:16.531478",
     "exception": false,
     "start_time": "2024-11-29T18:38:16.490513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pad_token: <unk>\n",
      "tokenizer.padding_side: left\n"
     ]
    }
   ],
   "source": [
    "print('tokenizer.pad_token:', tokenizer.pad_token)\n",
    "print('tokenizer.padding_side:', tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef2a599c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:16.613679Z",
     "iopub.status.busy": "2024-11-29T18:38:16.613199Z",
     "iopub.status.idle": "2024-11-29T18:38:40.204245Z",
     "shell.execute_reply": "2024-11-29T18:38:40.201726Z"
    },
    "papermill": {
     "duration": 23.642866,
     "end_time": "2024-11-29T18:38:40.209525",
     "exception": false,
     "start_time": "2024-11-29T18:38:16.566659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will use up to 0.0 out of 15.5 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 252.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\n",
    "    # f\"{project_root}/data/06_models/{user_id}/{pretrained_model_name}_unsloth_merged_16bit\",\n",
    "    f\"{cwd}/data/06_models/{user_id}/{pretrained_model_name}_unsloth_merged_16bit\",\n",
    "    save_method=\"merged_16bit\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec45dcde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:40.305739Z",
     "iopub.status.busy": "2024-11-29T18:38:40.304998Z",
     "iopub.status.idle": "2024-11-29T18:38:45.350717Z",
     "shell.execute_reply": "2024-11-29T18:38:45.349978Z"
    },
    "papermill": {
     "duration": 5.084268,
     "end_time": "2024-11-29T18:38:45.353877",
     "exception": false,
     "start_time": "2024-11-29T18:38:40.269609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documents': '[]',\n",
       " 'has_parallel_tool_calls': True,\n",
       " 'messages': '[{\"role\": \"user\", \"content\": \"What\\'s the weather like in San Francisco and New York?\"}, {\"role\": \"assistant\", \"tool_calls\": [{\"id\": \"call_0\", \"type\": \"function\", \"function\": {\"name\": \"get_current_weather\", \"arguments\": \"{\\\\\"location\\\\\": \\\\\"San Francisco, USA\\\\\", \\\\\"format\\\\\": \\\\\"celsius\\\\\"}\"}}, {\"id\": \"call_1\", \"type\": \"function\", \"function\": {\"name\": \"get_current_weather\", \"arguments\": \"{\\\\\"location\\\\\": \\\\\"New York, USA\\\\\", \\\\\"format\\\\\": \\\\\"celsius\\\\\"}\"}}]}, {\"role\": \"tool\", \"name\": \"get_current_weather\", \"tool_call_id\": \"call_0\", \"content\": \"21.0\"}, {\"role\": \"tool\", \"name\": \"get_current_weather\", \"tool_call_id\": \"call_1\", \"content\": \"18.5\"}, {\"role\": \"assistant\", \"content\": \"The current temperature in San Francisco is 21\\\\u00b0C (70\\\\u00b0F), while in New York it\\'s 18.5\\\\u00b0C (65\\\\u00b0F).\"}]',\n",
       " 'tools': '[{\"type\": \"function\", \"function\": {\"name\": \"get_current_weather\", \"description\": \"Get the current weather\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and country, eg. San Francisco, USA\"}, \"format\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}}, \"required\": [\"location\", \"format\"]}}}]'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dataset = load_dataset(\"mjschock/chat_threads\", split=\"train\")\n",
    "train_dataset = load_dataset(f\"{user_id}/chat_threads\", split=\"train\")\n",
    "# validation_dataset = load_dataset(\"mjschock/chat_threads\", split=\"validation\")\n",
    "validation_dataset = load_dataset(f\"{user_id}/chat_threads\", split=\"validation\")\n",
    "# test_dataset = load_dataset(\"mjschock/chat_threads\", split=\"test\")\n",
    "test_dataset = load_dataset(f\"{user_id}/chat_threads\", split=\"test\")\n",
    "\n",
    "test_example = test_dataset[0]\n",
    "test_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1157909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:45.460569Z",
     "iopub.status.busy": "2024-11-29T18:38:45.460040Z",
     "iopub.status.idle": "2024-11-29T18:38:45.467778Z",
     "shell.execute_reply": "2024-11-29T18:38:45.466521Z"
    },
    "papermill": {
     "duration": 0.075565,
     "end_time": "2024-11-29T18:38:45.471088",
     "exception": false,
     "start_time": "2024-11-29T18:38:45.395523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_example_documents = json.loads(test_example[\"documents\"])\n",
    "test_example_messages = json.loads(test_example[\"messages\"])\n",
    "test_example_tools = json.loads(test_example[\"tools\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c2b1cf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:45.571180Z",
     "iopub.status.busy": "2024-11-29T18:38:45.570612Z",
     "iopub.status.idle": "2024-11-29T18:38:45.578653Z",
     "shell.execute_reply": "2024-11-29T18:38:45.577258Z"
    },
    "papermill": {
     "duration": 0.063254,
     "end_time": "2024-11-29T18:38:45.580777",
     "exception": false,
     "start_time": "2024-11-29T18:38:45.517523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_example_messages:\n",
      "[{'content': \"What's the weather like in San Francisco and New York?\",\n",
      "  'role': 'user'},\n",
      " {'role': 'assistant',\n",
      "  'tool_calls': [{'function': {'arguments': '{\"location\": \"San Francisco, '\n",
      "                                            'USA\", \"format\": \"celsius\"}',\n",
      "                               'name': 'get_current_weather'},\n",
      "                  'id': 'call_0',\n",
      "                  'type': 'function'},\n",
      "                 {'function': {'arguments': '{\"location\": \"New York, USA\", '\n",
      "                                            '\"format\": \"celsius\"}',\n",
      "                               'name': 'get_current_weather'},\n",
      "                  'id': 'call_1',\n",
      "                  'type': 'function'}]},\n",
      " {'content': '21.0',\n",
      "  'name': 'get_current_weather',\n",
      "  'role': 'tool',\n",
      "  'tool_call_id': 'call_0'},\n",
      " {'content': '18.5',\n",
      "  'name': 'get_current_weather',\n",
      "  'role': 'tool',\n",
      "  'tool_call_id': 'call_1'},\n",
      " {'content': 'The current temperature in San Francisco is 21°C (70°F), while '\n",
      "             \"in New York it's 18.5°C (65°F).\",\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "print('test_example_messages:')\n",
    "pprint(test_example_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d7f8d43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:45.669835Z",
     "iopub.status.busy": "2024-11-29T18:38:45.669362Z",
     "iopub.status.idle": "2024-11-29T18:38:45.674198Z",
     "shell.execute_reply": "2024-11-29T18:38:45.673562Z"
    },
    "papermill": {
     "duration": 0.049312,
     "end_time": "2024-11-29T18:38:45.675374",
     "exception": false,
     "start_time": "2024-11-29T18:38:45.626062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_example_tools:\n",
      "[{'function': {'description': 'Get the current weather',\n",
      "               'name': 'get_current_weather',\n",
      "               'parameters': {'properties': {'format': {'enum': ['celsius',\n",
      "                                                                 'fahrenheit'],\n",
      "                                                        'type': 'string'},\n",
      "                                             'location': {'description': 'The '\n",
      "                                                                         'city '\n",
      "                                                                         'and '\n",
      "                                                                         'country, '\n",
      "                                                                         'eg. '\n",
      "                                                                         'San '\n",
      "                                                                         'Francisco, '\n",
      "                                                                         'USA',\n",
      "                                                          'type': 'string'}},\n",
      "                              'required': ['location', 'format'],\n",
      "                              'type': 'object'}},\n",
      "  'type': 'function'}]\n"
     ]
    }
   ],
   "source": [
    "print('test_example_tools:')\n",
    "pprint(test_example_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "415f20ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:45.734410Z",
     "iopub.status.busy": "2024-11-29T18:38:45.734036Z",
     "iopub.status.idle": "2024-11-29T18:38:45.755117Z",
     "shell.execute_reply": "2024-11-29T18:38:45.754368Z"
    },
    "papermill": {
     "duration": 0.051292,
     "end_time": "2024-11-29T18:38:45.756353",
     "exception": false,
     "start_time": "2024-11-29T18:38:45.705061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = tokenizer.apply_chat_template(\n",
    "    add_generation_prompt=True,\n",
    "    conversation=test_example_messages[0:1], # Only the user message, note that the system message will automatically be added\n",
    "    documents=test_example_documents,\n",
    "    tools=test_example_tools,\n",
    "    tokenize=False,\n",
    ")\n",
    "\n",
    "prompt_and_response = tokenizer.apply_chat_template(\n",
    "    add_generation_prompt=False,\n",
    "    conversation=test_example_messages[0:2], # Only the user and first assistant message, note that the system message will automatically be added\n",
    "    documents=test_example_documents,\n",
    "    tools=test_example_tools,\n",
    "    tokenize=False,\n",
    ")\n",
    "\n",
    "response = prompt_and_response.replace(prompt, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daa26b02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:45.830290Z",
     "iopub.status.busy": "2024-11-29T18:38:45.829924Z",
     "iopub.status.idle": "2024-11-29T18:38:45.836823Z",
     "shell.execute_reply": "2024-11-29T18:38:45.835633Z"
    },
    "papermill": {
     "duration": 0.04677,
     "end_time": "2024-11-29T18:38:45.838786",
     "exception": false,
     "start_time": "2024-11-29T18:38:45.792016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "<s><|system|>\n",
      "You are an AI agent acting as a human assistant.\n",
      "\n",
      "You are aware of the following tools in your environment:\n",
      "{\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"function\": {\n",
      "        \"description\": \"Get the current weather\",\n",
      "        \"name\": \"get_current_weather\",\n",
      "        \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and country, eg. San Francisco, USA\"}, \"format\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}}, \"required\": [\"location\", \"format\"]}\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "If you would like to suggest one or more tool calls, please respond in the following format:\n",
      "{\n",
      "  \"finish_reason\": \"tool_calls\",\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"arguments\": \"{\\\"parameter_name\\\": \\\"parameter_value\\\"}\",\n",
      "      \"id\": \"call_id\",\n",
      "      \"name\": \"tool_name\"\n",
      "    }\n",
      "  ]\n",
      "}</s>\n",
      "<|user|>\n",
      "What's the weather like in San Francisco and New York?</s>\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('prompt:')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b154ebfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:45.906889Z",
     "iopub.status.busy": "2024-11-29T18:38:45.906432Z",
     "iopub.status.idle": "2024-11-29T18:38:45.911744Z",
     "shell.execute_reply": "2024-11-29T18:38:45.910753Z"
    },
    "papermill": {
     "duration": 0.040456,
     "end_time": "2024-11-29T18:38:45.913036",
     "exception": false,
     "start_time": "2024-11-29T18:38:45.872580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response (ground truth):\n",
      "{\n",
      "  \"finish_reason\": \"tool_calls\",\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"arguments\": \"{\\\"location\\\": \\\"San Francisco, USA\\\", \\\"format\\\": \\\"celsius\\\"}\",\n",
      "      \"id\": \"call_0\",\n",
      "      \"name\": \"get_current_weather\"\n",
      "    },\n",
      "    {\n",
      "      \"arguments\": \"{\\\"location\\\": \\\"New York, USA\\\", \\\"format\\\": \\\"celsius\\\"}\",\n",
      "      \"id\": \"call_1\",\n",
      "      \"name\": \"get_current_weather\"\n",
      "    }\n",
      "  ]\n",
      "}</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"response (ground truth):\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83be9db7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:45.992237Z",
     "iopub.status.busy": "2024-11-29T18:38:45.991909Z",
     "iopub.status.idle": "2024-11-29T18:38:46.218019Z",
     "shell.execute_reply": "2024-11-29T18:38:46.216732Z"
    },
    "papermill": {
     "duration": 0.271774,
     "end_time": "2024-11-29T18:38:46.219781",
     "exception": false,
     "start_time": "2024-11-29T18:38:45.948007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b6da95c7b44e88a7ab6611986afbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_and_preprocess_data(dataset, tokenizer):\n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset for training.\n",
    "\n",
    "    Args:\n",
    "        dataset: The dataset to preprocess\n",
    "        tokenizer: Tokenizer to use for preprocessing.\n",
    "\n",
    "    Returns:\n",
    "        datasets.Dataset: Preprocessed dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        # Extract the messages from the example\n",
    "        conversation = examples[\"messages\"]\n",
    "        documents = examples.get(\"documents\", [])\n",
    "        tools = examples.get(\"tools\", [])\n",
    "\n",
    "        # Apply chat template to generate tokenized input and assistant mask\n",
    "        tokenized_output = tokenizer.apply_chat_template(\n",
    "            add_generation_prompt=False,\n",
    "            conversation=json.loads(conversation),\n",
    "            documents=json.loads(documents),\n",
    "            max_length=max_seq_length,\n",
    "            padding=\"longest\",\n",
    "            return_assistant_tokens_mask=True,\n",
    "            return_dict=True,\n",
    "            return_tensors=\"pt\",\n",
    "            tokenize=True,\n",
    "            tools=json.loads(tools),\n",
    "            truncation=True,  # TODO: verify we're not truncating anything in the datasets\n",
    "        )\n",
    "\n",
    "        # Extract the input IDs and assistant tokens mask\n",
    "        input_ids = tokenized_output[\"input_ids\"][0]\n",
    "        assistant_masks = torch.tensor(tokenized_output[\"assistant_masks\"])\n",
    "        attention_mask = tokenized_output[\"attention_mask\"][0]\n",
    "\n",
    "        # Use the assistant mask to create labels\n",
    "        labels = torch.where(assistant_masks == 1, input_ids, torch.tensor(-100))\n",
    "\n",
    "        return {\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "    # Preprocess the dataset\n",
    "    return dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=False,\n",
    "        num_proc=1,\n",
    "        remove_columns=dataset.column_names,\n",
    "    )  # TODO: use batched=True\n",
    "\n",
    "\n",
    "tokenized_train_dataset = load_and_preprocess_data(\n",
    "    train_dataset,\n",
    "    tokenizer,\n",
    ")\n",
    "\n",
    "tokenized_validation_dataset = load_and_preprocess_data(\n",
    "    validation_dataset,\n",
    "    tokenizer,\n",
    ")\n",
    "\n",
    "tokenized_test_dataset = load_and_preprocess_data(\n",
    "    test_dataset,\n",
    "    tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "545fd3fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:46.304033Z",
     "iopub.status.busy": "2024-11-29T18:38:46.303449Z",
     "iopub.status.idle": "2024-11-29T18:38:46.309944Z",
     "shell.execute_reply": "2024-11-29T18:38:46.308974Z"
    },
    "papermill": {
     "duration": 0.054027,
     "end_time": "2024-11-29T18:38:46.311338",
     "exception": false,
     "start_time": "2024-11-29T18:38:46.257311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_test_prediction():\n",
    "    FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        add_generation_prompt=True,\n",
    "        conversation=test_example_messages[0:1], # Only the user message, note that the system message will automatically be added\n",
    "        documents=test_example_documents,\n",
    "        tools=test_example_tools,\n",
    "        return_tensors=\"pt\",\n",
    "        tokenize=True,\n",
    "    ).to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        do_sample=False,\n",
    "        input_ids=inputs,\n",
    "        max_new_tokens=256,\n",
    "        use_cache=True,\n",
    "        # temperature=0.0,\n",
    "    )\n",
    "\n",
    "    batch_decoded_outputs = tokenizer.batch_decode(outputs)\n",
    "\n",
    "    prompt = batch_decoded_outputs[0][0:len(tokenizer.decode(inputs[0]))]\n",
    "    response = batch_decoded_outputs[0][len(tokenizer.decode(inputs[0])):]\n",
    "\n",
    "    return prompt, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01537ae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:46.385261Z",
     "iopub.status.busy": "2024-11-29T18:38:46.384770Z",
     "iopub.status.idle": "2024-11-29T18:38:53.268903Z",
     "shell.execute_reply": "2024-11-29T18:38:53.268087Z"
    },
    "papermill": {
     "duration": 6.921335,
     "end_time": "2024-11-29T18:38:53.270419",
     "exception": false,
     "start_time": "2024-11-29T18:38:46.349084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "prompt, response = generate_test_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e862f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:53.344240Z",
     "iopub.status.busy": "2024-11-29T18:38:53.343906Z",
     "iopub.status.idle": "2024-11-29T18:38:53.348119Z",
     "shell.execute_reply": "2024-11-29T18:38:53.347511Z"
    },
    "papermill": {
     "duration": 0.048876,
     "end_time": "2024-11-29T18:38:53.349361",
     "exception": false,
     "start_time": "2024-11-29T18:38:53.300485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pad_token: <unk>\n",
      "tokenizer.padding_side: left\n"
     ]
    }
   ],
   "source": [
    "print('tokenizer.pad_token:', tokenizer.pad_token)\n",
    "print('tokenizer.padding_side:', tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dd39c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:53.410543Z",
     "iopub.status.busy": "2024-11-29T18:38:53.410263Z",
     "iopub.status.idle": "2024-11-29T18:38:53.415030Z",
     "shell.execute_reply": "2024-11-29T18:38:53.414049Z"
    },
    "papermill": {
     "duration": 0.036642,
     "end_time": "2024-11-29T18:38:53.416518",
     "exception": false,
     "start_time": "2024-11-29T18:38:53.379876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "<s> <|system|>\n",
      "You are an AI agent acting as a human assistant.\n",
      "\n",
      "You are aware of the following tools in your environment:\n",
      "{\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"function\": {\n",
      "        \"description\": \"Get the current weather\",\n",
      "        \"name\": \"get_current_weather\",\n",
      "        \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and country, eg. San Francisco, USA\"}, \"format\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}}, \"required\": [\"location\", \"format\"]}\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "If you would like to suggest one or more tool calls, please respond in the following format:\n",
      "{\n",
      "  \"finish_reason\": \"tool_calls\",\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"arguments\": \"{\\\"parameter_name\\\": \\\"parameter_value\\\"}\",\n",
      "      \"id\": \"call_id\",\n",
      "      \"name\": \"tool_name\"\n",
      "    }\n",
      "  ]\n",
      "}</s> \n",
      "<|user|>\n",
      "What's the weather like in San Francisco and New York?</s> \n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('prompt:')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03c6d845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:53.488940Z",
     "iopub.status.busy": "2024-11-29T18:38:53.488500Z",
     "iopub.status.idle": "2024-11-29T18:38:53.493969Z",
     "shell.execute_reply": "2024-11-29T18:38:53.493072Z"
    },
    "papermill": {
     "duration": 0.050281,
     "end_time": "2024-11-29T18:38:53.495576",
     "exception": false,
     "start_time": "2024-11-29T18:38:53.445295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response (predicted, before training):\n",
      "I don't have access to real-time weather data, but according to the information available data, the weather in san francisco and new york are both hot and humid. San francisco has a maximum temperature of 328.8°c (992.8f) and minimum of 25.8°c (439.2f, while new york has maximum of 39.8° (434.2f and minimum 2.8° (32f).</s>\n"
     ]
    }
   ],
   "source": [
    "print('response (predicted, before training):')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0903b24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:53.555416Z",
     "iopub.status.busy": "2024-11-29T18:38:53.555044Z",
     "iopub.status.idle": "2024-11-29T18:38:56.388290Z",
     "shell.execute_reply": "2024-11-29T18:38:56.387495Z"
    },
    "id": "6bZsfBuZDeCL",
    "outputId": "b630cc80-ff95-45a2-cc0d-38666010d73b",
    "papermill": {
     "duration": 2.863249,
     "end_time": "2024-11-29T18:38:56.389792",
     "exception": false,
     "start_time": "2024-11-29T18:38:53.526543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Offloading output_embeddings to disk to save VRAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mjschock/Projects/training-tinyllama-for-tool-calling/.venv/lib/python3.10/site-packages/unsloth/models/_utils.py:689: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  offloaded_W = torch.load(filename, map_location = \"cpu\", mmap = True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.11.5 patched 22 layers with 22 QKV layers, 22 O layers and 22 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Training lm_head in mixed precision to save VRAM\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    bias=\"none\",\n",
    "    loftq_config=None,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0,\n",
    "    model=model,\n",
    "    r=16,\n",
    "    random_state=42,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    use_rslora=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72568622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:56.487778Z",
     "iopub.status.busy": "2024-11-29T18:38:56.487209Z",
     "iopub.status.idle": "2024-11-29T18:38:56.494069Z",
     "shell.execute_reply": "2024-11-29T18:38:56.493204Z"
    },
    "papermill": {
     "duration": 0.072727,
     "end_time": "2024-11-29T18:38:56.495424",
     "exception": false,
     "start_time": "2024-11-29T18:38:56.422697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pad_token: <unk>\n",
      "tokenizer.padding_side: right\n"
     ]
    }
   ],
   "source": [
    "print('tokenizer.pad_token:', tokenizer.pad_token)\n",
    "print('tokenizer.padding_side:', tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82c5c384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:38:56.588926Z",
     "iopub.status.busy": "2024-11-29T18:38:56.587841Z",
     "iopub.status.idle": "2024-11-29T18:39:00.326385Z",
     "shell.execute_reply": "2024-11-29T18:39:00.325649Z"
    },
    "id": "95_Nn-89DhsL",
    "outputId": "4b809e6d-271f-446f-dec8-abe0d13259f8",
    "papermill": {
     "duration": 3.779182,
     "end_time": "2024-11-29T18:39:00.327834",
     "exception": false,
     "start_time": "2024-11-29T18:38:56.548652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/mjschock/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/mjschock/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/mjschock/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate.combine([\"accuracy\", \"bleu\", \"meteor\", \"rouge\"])\n",
    "metrics_tracker = {}\n",
    "\n",
    "def compute_metrics(eval_pred: EvalPrediction, compute_result: bool) -> Dict:\n",
    "    assert isinstance(\n",
    "        eval_pred, EvalPrediction\n",
    "    ), f\"Expected EvalPrediction, got {type(eval_pred)}\"\n",
    "\n",
    "    all_labels = eval_pred.label_ids\n",
    "    all_preds = eval_pred.predictions\n",
    "    is_last_step = compute_result\n",
    "\n",
    "    all_labels[all_labels == -100] = tokenizer.pad_token_id\n",
    "    references: List[str] = tokenizer.batch_decode(\n",
    "        all_labels, skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    assert (\n",
    "        all_preds.shape == all_labels.shape\n",
    "    ), f\"Expected predictions and labels to have the same shape, got {all_preds.shape} and {all_labels.shape}\"\n",
    "\n",
    "    predictions: List[str] = tokenizer.batch_decode(\n",
    "        all_preds, skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    assert len(predictions) == len(\n",
    "        references\n",
    "    ), f\"Expected predictions and references to have the same length, got {len(predictions)} and {len(references)}\"\n",
    "\n",
    "    eval_batch_metrics = metrics.compute(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "\n",
    "    computed_metrics = {}\n",
    "\n",
    "    for key, value in eval_batch_metrics.items():\n",
    "        if type(value) in [list, np.ndarray]:\n",
    "            value = np.mean(value)\n",
    "\n",
    "        metrics_tracker[key] = np.mean([metrics_tracker.get(key, 0.0), value])\n",
    "        computed_metrics[key] = metrics_tracker[key]\n",
    "\n",
    "        if is_last_step:\n",
    "            metrics_tracker[key] = 0.0\n",
    "\n",
    "    return computed_metrics\n",
    "\n",
    "def preprocess_logits_for_metrics(\n",
    "    logits: torch.Tensor, labels: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Original Trainer may have a memory leak.\n",
    "    This is a workaround to avoid storing too many tensors that are not needed.\n",
    "    \"\"\"\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    return pred_ids\n",
    "\n",
    "sft_trainer = SFTTrainer(\n",
    "    args=SFTConfig(\n",
    "        # auto_find_batch_size=True,\n",
    "        # batch_eval_metrics=True,\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        # eval_accumulation_steps=16,\n",
    "        # eval_on_start=True,\n",
    "        # eval_steps=1.0,\n",
    "        # eval_strategy=\"epoch\",\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        # gradient_accumulation_steps=16,\n",
    "        gradient_accumulation_steps=4,\n",
    "        # gradient_checkpointing=\"unsloth\",\n",
    "        # learning_rate=5e-05,\n",
    "        learning_rate=2e-4,\n",
    "        # load_best_model_at_end=True,\n",
    "        logging_steps=1.0,\n",
    "        # logging_strategy=\"steps\",\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        # max_seq_length=max_seq_length,\n",
    "        # max_steps=60,\n",
    "        # max_steps=3,\n",
    "        max_steps=1,\n",
    "        # num_of_sequences=1,\n",
    "        # num_train_epochs=3.0,\n",
    "        # num_train_epochs=1.0,\n",
    "        optim=\"adamw_8bit\",\n",
    "        # output_dir=\"outputs\",\n",
    "        # output_dir=\"data/06_models/model\",\n",
    "        # output_dir=\"data/06_models/model/checkpoints\",\n",
    "        # output_dir=os.path.join(project_root, \"data/06_models/mjschock/TinyLlama-1.1B-Chat-v1.0_merged_16bit/checkpoints\"),\n",
    "        # output_dir=os.path.join(project_root, \"data/06_models/mjschock/TinyLlama-1.1B-Chat-v1.0-tool-calling-sft/checkpoints\"),\n",
    "        # output_dir=f\"{project_root}/data/06_models/{user_id}/{pretrained_model_name}_tool-calling-sft/checkpoints\",\n",
    "        output_dir=f\"{cwd}/data/06_models/{user_id}/{pretrained_model_name}_tool-calling-sft/checkpoints\",\n",
    "        overwrite_output_dir=True,\n",
    "        # packing=False,\n",
    "        per_device_eval_batch_size=1,\n",
    "        per_device_train_batch_size=1,\n",
    "        # push_to_hub=False,\n",
    "        report_to=\"mlflow\",\n",
    "        # save_steps=1.0,\n",
    "        # save_strategy=\"epoch\",\n",
    "        # save_total_limit=1,\n",
    "        seed=42,\n",
    "        warmup_steps=5,\n",
    "        weight_decay=0.01,\n",
    "    ),\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorForLanguageModeling(mlm=False, tokenizer=tokenizer),\n",
    "    dataset_num_proc=1,\n",
    "    eval_dataset=tokenized_validation_dataset,\n",
    "    max_seq_length=max_seq_length,\n",
    "    model=model,\n",
    "    packing=False,  # Can make training 5x faster for short sequences.\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    ")\n",
    "\n",
    "# dpo_trainer = DPOTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5aa642a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:00.402841Z",
     "iopub.status.busy": "2024-11-29T18:39:00.402436Z",
     "iopub.status.idle": "2024-11-29T18:39:00.408263Z",
     "shell.execute_reply": "2024-11-29T18:39:00.407045Z"
    },
    "papermill": {
     "duration": 0.051911,
     "end_time": "2024-11-29T18:39:00.410501",
     "exception": false,
     "start_time": "2024-11-29T18:39:00.358590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pad_token: <unk>\n",
      "tokenizer.padding_side: right\n"
     ]
    }
   ],
   "source": [
    "print('tokenizer.pad_token:', tokenizer.pad_token)\n",
    "print('tokenizer.padding_side:', tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34449d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:00.484457Z",
     "iopub.status.busy": "2024-11-29T18:39:00.482431Z",
     "iopub.status.idle": "2024-11-29T18:39:00.514722Z",
     "shell.execute_reply": "2024-11-29T18:39:00.513790Z"
    },
    "papermill": {
     "duration": 0.072111,
     "end_time": "2024-11-29T18:39:00.516820",
     "exception": false,
     "start_time": "2024-11-29T18:39:00.444709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> <|system|>\\nYou are an intelligent AI that controls a drone. Given a command or request from the user,\\ncall one of your functions to complete the request. If the request cannot be completed by your available functions, call the reject_request function.\\nIf the request is ambiguous or unclear, reject the request.\\n\\nYou are aware of the following tools in your environment:\\n{\\n  \"tools\": [\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"takeoff_drone\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"altitude\": {\"type\": \"integer\"}}, \"required\": [\"altitude\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"land_drone\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"enum\": [\"current\", \"home_base\", \"custom\"]}, \"coordinates\": {\"type\": \"object\"}}, \"required\": [\"location\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"control_drone_movement\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"direction\": {\"type\": \"string\", \"enum\": [\"forward\", \"backward\", \"left\", \"right\", \"up\", \"down\"]}, \"distance\": {\"type\": \"integer\"}}, \"required\": [\"direction\", \"distance\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"set_drone_speed\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"speed\": {\"type\": \"integer\", \"minimum\": 0}}, \"required\": [\"speed\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"control_camera\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"mode\": {\"type\": \"string\", \"enum\": [\"photo\", \"video\", \"panorama\"]}, \"duration\": {\"type\": \"integer\"}}, \"required\": [\"mode\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"control_gimbal\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"tilt\": {\"type\": \"integer\"}, \"pan\": {\"type\": \"integer\"}}, \"required\": [\"tilt\", \"pan\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"set_drone_lighting\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"mode\": {\"type\": \"string\", \"enum\": [\"on\", \"off\", \"blink\", \"sos\"]}}, \"required\": [\"mode\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"return_to_home\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {}}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"set_battery_saver_mode\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"status\": {\"type\": \"string\", \"enum\": [\"on\", \"off\"]}}, \"required\": [\"status\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"set_obstacle_avoidance\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"mode\": {\"type\": \"string\", \"enum\": [\"on\", \"off\"]}}, \"required\": [\"mode\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"set_follow_me_mode\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"status\": {\"type\": \"string\", \"enum\": [\"on\", \"off\"]}}, \"required\": [\"status\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"calibrate_sensors\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {}}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"set_autopilot\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"status\": {\"type\": \"string\", \"enum\": [\"on\", \"off\"]}}, \"required\": [\"status\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"configure_led_display\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"pattern\": {\"type\": \"string\", \"enum\": [\"solid\", \"blink\", \"pulse\", \"rainbow\"]}, \"color\": {\"type\": \"string\", \"enum\": [\"red\", \"blue\", \"green\", \"yellow\", \"white\"]}}, \"required\": [\"pattern\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"set_home_location\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {\"coordinates\": {\"type\": \"object\"}}, \"required\": [\"coordinates\"]}\\n      },\\n      \"type\": \"function\"\\n    },\\n    {\\n      \"function\": {\\n        \"description\": \"\",\\n        \"name\": \"reject_request\",\\n        \"parameters\": {\"type\": \"object\", \"properties\": {}}\\n      },\\n      \"type\": \"function\"\\n    }\\n  ]\\n}\\n\\nIf you would like to suggest one or more tool calls, please respond in the following format:\\n{\\n  \"finish_reason\": \"tool_calls\",\\n  \"tool_calls\": [\\n    {\\n      \"arguments\": \"{\\\\\"parameter_name\\\\\": \\\\\"parameter_value\\\\\"}\",\\n      \"id\": \"call_id\",\\n      \"name\": \"tool_name\"\\n    }\\n  ]\\n}</s> \\n<|user|>\\nMy phone battery is draining so fast, can you turn on battery saver mode</s> \\n<|assistant|>\\n{\\n  \"finish_reason\": \"tool_calls\",\\n  \"tool_calls\": [\\n    {\\n      \"arguments\": \"{\\\\\"status\\\\\": \\\\\"on\\\\\"}\",\\n      \"id\": \"call_id\",\\n      \"name\": \"set_battery_saver_mode\"\\n    }\\n  ]\\n}</s> \\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the first training example. When we decod the input_ids, we'll see the full chat history.\n",
    "\n",
    "tokenizer.decode(sft_trainer.train_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4de089c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:00.607592Z",
     "iopub.status.busy": "2024-11-29T18:39:00.607112Z",
     "iopub.status.idle": "2024-11-29T18:39:00.631330Z",
     "shell.execute_reply": "2024-11-29T18:39:00.630513Z"
    },
    "papermill": {
     "duration": 0.069546,
     "end_time": "2024-11-29T18:39:00.632679",
     "exception": false,
     "start_time": "2024-11-29T18:39:00.563133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {\\n  \"finish_reason\": \"tool_calls\",\\n  \"tool_calls\": [\\n    {\\n      \"arguments\": \"{\\\\\"status\\\\\": \\\\\"on\\\\\"}\",\\n      \"id\": \"call_id\",\\n      \"name\": \"set_battery_saver_mode\"\\n    }\\n  ]\\n}      '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's take a look at the labels. The labels are the same as the input_ids, except that the assistant tokens are replaced with -100. This is because we want to predict the assistant tokens.\n",
    "\n",
    "space = tokenizer(\" \", add_special_tokens=False).input_ids[0]\n",
    "tokenizer.decode(\n",
    "    [space if x == -100 else x for x in sft_trainer.train_dataset[0][\"labels\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e44228da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:00.713109Z",
     "iopub.status.busy": "2024-11-29T18:39:00.711300Z",
     "iopub.status.idle": "2024-11-29T18:39:00.721794Z",
     "shell.execute_reply": "2024-11-29T18:39:00.720786Z"
    },
    "papermill": {
     "duration": 0.057824,
     "end_time": "2024-11-29T18:39:00.723660",
     "exception": false,
     "start_time": "2024-11-29T18:39:00.665836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce GTX 1050 Ti. Max memory = 3.94 GB.\n",
      "2.592 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e45b8339",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:00.794892Z",
     "iopub.status.busy": "2024-11-29T18:39:00.793993Z",
     "iopub.status.idle": "2024-11-29T18:39:35.996745Z",
     "shell.execute_reply": "2024-11-29T18:39:35.995633Z"
    },
    "id": "yqxqAZ7KJ4oL",
    "outputId": "3cf26aac-6042-4458-c4a6-d8849efb6a95",
    "papermill": {
     "duration": 35.238373,
     "end_time": "2024-11-29T18:39:35.998334",
     "exception": false,
     "start_time": "2024-11-29T18:39:00.759961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 239 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 4 | Total steps = 1\n",
      " \"-____-\"     Number of trainable parameters = 78,151,680\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:01, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.771500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer_stats:\n",
      "TrainOutput(global_step=1, training_loss=1.7715449333190918, metrics={'train_runtime': 32.8106, 'train_samples_per_second': 0.122, 'train_steps_per_second': 0.03, 'total_flos': 17350883414016.0, 'train_loss': 1.7715449333190918, 'epoch': 0.016736401673640166})\n"
     ]
    }
   ],
   "source": [
    "# with mlflow.start_run(\n",
    "    # experiment_id=experiment.experiment_id,\n",
    "#     nested=True,\n",
    "# ):\n",
    "trainer_stats = sft_trainer.train(\n",
    "    resume_from_checkpoint=False,\n",
    "    trial=None,\n",
    ")\n",
    "\n",
    "print('trainer_stats:')\n",
    "pprint(trainer_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15f8a81c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:36.086175Z",
     "iopub.status.busy": "2024-11-29T18:39:36.085716Z",
     "iopub.status.idle": "2024-11-29T18:39:36.093764Z",
     "shell.execute_reply": "2024-11-29T18:39:36.092663Z"
    },
    "papermill": {
     "duration": 0.066555,
     "end_time": "2024-11-29T18:39:36.095257",
     "exception": false,
     "start_time": "2024-11-29T18:39:36.028702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.8106 seconds used for training.\n",
      "0.55 minutes used for training.\n",
      "Peak reserved memory = 2.592 GB.\n",
      "Peak reserved memory for training = 0.0 GB.\n",
      "Peak reserved memory % of max memory = 65.787 %.\n",
      "Peak reserved memory for training % of max memory = 0.0 %.\n"
     ]
    }
   ],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1c30e20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:36.161499Z",
     "iopub.status.busy": "2024-11-29T18:39:36.161209Z",
     "iopub.status.idle": "2024-11-29T18:39:36.166457Z",
     "shell.execute_reply": "2024-11-29T18:39:36.165409Z"
    },
    "papermill": {
     "duration": 0.040071,
     "end_time": "2024-11-29T18:39:36.168045",
     "exception": false,
     "start_time": "2024-11-29T18:39:36.127974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pad_token: <unk>\n",
      "tokenizer.padding_side: right\n"
     ]
    }
   ],
   "source": [
    "print('tokenizer.pad_token:', tokenizer.pad_token)\n",
    "print('tokenizer.padding_side:', tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bb346ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:36.242797Z",
     "iopub.status.busy": "2024-11-29T18:39:36.241747Z",
     "iopub.status.idle": "2024-11-29T18:39:42.278300Z",
     "shell.execute_reply": "2024-11-29T18:39:42.277479Z"
    },
    "papermill": {
     "duration": 6.07927,
     "end_time": "2024-11-29T18:39:42.280217",
     "exception": false,
     "start_time": "2024-11-29T18:39:36.200947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt, response = generate_test_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "436a1262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:42.372596Z",
     "iopub.status.busy": "2024-11-29T18:39:42.372289Z",
     "iopub.status.idle": "2024-11-29T18:39:42.377191Z",
     "shell.execute_reply": "2024-11-29T18:39:42.376326Z"
    },
    "papermill": {
     "duration": 0.066317,
     "end_time": "2024-11-29T18:39:42.379000",
     "exception": false,
     "start_time": "2024-11-29T18:39:42.312683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "<s> <|system|>\n",
      "You are an AI agent acting as a human assistant.\n",
      "\n",
      "You are aware of the following tools in your environment:\n",
      "{\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"function\": {\n",
      "        \"description\": \"Get the current weather\",\n",
      "        \"name\": \"get_current_weather\",\n",
      "        \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and country, eg. San Francisco, USA\"}, \"format\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}}, \"required\": [\"location\", \"format\"]}\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "If you would like to suggest one or more tool calls, please respond in the following format:\n",
      "{\n",
      "  \"finish_reason\": \"tool_calls\",\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"arguments\": \"{\\\"parameter_name\\\": \\\"parameter_value\\\"}\",\n",
      "      \"id\": \"call_id\",\n",
      "      \"name\": \"tool_name\"\n",
      "    }\n",
      "  ]\n",
      "}</s> \n",
      "<|user|>\n",
      "What's the weather like in San Francisco and New York?</s> \n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('prompt:')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ef9ec8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:42.443775Z",
     "iopub.status.busy": "2024-11-29T18:39:42.443439Z",
     "iopub.status.idle": "2024-11-29T18:39:42.448235Z",
     "shell.execute_reply": "2024-11-29T18:39:42.447247Z"
    },
    "papermill": {
     "duration": 0.038588,
     "end_time": "2024-11-29T18:39:42.449610",
     "exception": false,
     "start_time": "2024-11-29T18:39:42.411022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response (predicted, after training):\n",
      "I don't have access to real-time weather data, but according to the information available data, the weather in san francisco and new york are both hot and humid. San francisco has a maximum temperature of 328.8°c (992.8f) and minimum of 25.8°c (439.2f, while new york has maximum of 39.8° (434.2f and minimum 2.8° (32f).</s>\n"
     ]
    }
   ],
   "source": [
    "print('response (predicted, after training):')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "675562d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:42.539794Z",
     "iopub.status.busy": "2024-11-29T18:39:42.539402Z",
     "iopub.status.idle": "2024-11-29T18:39:42.544539Z",
     "shell.execute_reply": "2024-11-29T18:39:42.543590Z"
    },
    "papermill": {
     "duration": 0.063713,
     "end_time": "2024-11-29T18:39:42.546322",
     "exception": false,
     "start_time": "2024-11-29T18:39:42.482609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pad_token: <unk>\n",
      "tokenizer.padding_side: left\n"
     ]
    }
   ],
   "source": [
    "print('tokenizer.pad_token:', tokenizer.pad_token)\n",
    "print('tokenizer.padding_side:', tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a92a7d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:42.613845Z",
     "iopub.status.busy": "2024-11-29T18:39:42.613512Z",
     "iopub.status.idle": "2024-11-29T18:39:44.168623Z",
     "shell.execute_reply": "2024-11-29T18:39:44.167740Z"
    },
    "papermill": {
     "duration": 1.591921,
     "end_time": "2024-11-29T18:39:44.170194",
     "exception": false,
     "start_time": "2024-11-29T18:39:42.578273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    # model.save_pretrained(\"lora_model\")  # Local saving\n",
    "    # model.save_pretrained(\"data/06_models/model/lora\")  # Local saving\n",
    "    # model.save_pretrained(os.path.join(project_root, \"data/06_models/mjschock/TinyLlama-1.1B-Chat-v1.0-tool-calling-sft/lora\"))  # Local saving\n",
    "    # model.save_pretrained(f\"{project_root}/data/06_models/{user_id}/{pretrained_model_name}-tool-calling-sft/lora\"), # Local saving\n",
    "    model.save_pretrained(f\"{cwd}/data/06_models/{user_id}/{pretrained_model_name}-tool-calling-sft/lora\") # Local saving\n",
    "    # tokenizer.save_pretrained(\"lora_model\")\n",
    "    # tokenizer.save_pretrained(\"data/06_models/model/lora\")\n",
    "    # tokenizer.save_pretrained(os.path.join(project_root, \"data/06_models/mjschock/TinyLlama-1.1B-Chat-v1.0-tool-calling-sft/lora\"))\n",
    "    # tokenizer.save_pretrained(f\"{project_root}/data/06_models/{user_id}/{pretrained_model_name}-tool-calling-sft/lora\") # Local saving\n",
    "    tokenizer.save_pretrained(f\"{cwd}/data/06_models/{user_id}/{pretrained_model_name}-tool-calling-sft/lora\") # Local saving\n",
    "\n",
    "else:\n",
    "    # TODO: push to hub\n",
    "    raise NotImplementedError(\"Pushing to hub is not implemented yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4edb01e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:44.271303Z",
     "iopub.status.busy": "2024-11-29T18:39:44.270635Z",
     "iopub.status.idle": "2024-11-29T18:39:44.278693Z",
     "shell.execute_reply": "2024-11-29T18:39:44.277358Z"
    },
    "papermill": {
     "duration": 0.071333,
     "end_time": "2024-11-29T18:39:44.281218",
     "exception": false,
     "start_time": "2024-11-29T18:39:44.209885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pad_token: <unk>\n",
      "tokenizer.padding_side: left\n"
     ]
    }
   ],
   "source": [
    "print('tokenizer.pad_token:', tokenizer.pad_token)\n",
    "print('tokenizer.padding_side:', tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f56b493f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:39:44.391076Z",
     "iopub.status.busy": "2024-11-29T18:39:44.390817Z",
     "iopub.status.idle": "2024-11-29T18:40:16.105525Z",
     "shell.execute_reply": "2024-11-29T18:40:16.104717Z"
    },
    "papermill": {
     "duration": 31.769979,
     "end_time": "2024-11-29T18:40:16.111469",
     "exception": false,
     "start_time": "2024-11-29T18:39:44.341490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 0.0 out of 15.5 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████████▊                                                                                                                      | 2/22 [00:00<00:01, 18.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████████████████████████▌                                                                                                    | 5/22 [00:00<00:00, 23.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███████████████████████████████████████████████▎                                                                                  | 8/22 [00:00<00:00, 25.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████████████████████████████▌                                                                | 11/22 [00:00<00:00, 25.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████████████████████████████████████████████████████████████                                               | 14/22 [00:00<00:00, 26.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 17/22 [00:00<00:00, 26.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 20/22 [00:00<00:00, 27.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 26.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done.\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    model.save_pretrained_merged(\n",
    "        # os.path.join(project_root, \"data/06_models/mjschock/TinyLlama-1.1B-Chat-v1.0-tool-calling-sft/merged_16bit\"),\n",
    "        # f\"{project_root}/data/06_models/{user_id}/{pretrained_model_name}-tool-calling-sft/unsloth_merged_16bit\",\n",
    "        f\"{cwd}/data/06_models/{user_id}/{pretrained_model_name}-tool-calling-sft/unsloth_merged_16bit\",\n",
    "        save_method=\"merged_16bit\",\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    # model.save_pretrained_merged(\n",
    "    #     os.path.join(project_root, \"data/06_models/mjschock/TinyLlama-1.1B-Chat-v1.0-tool-calling-sft/merged_4bit\"),\n",
    "    #     save_method=\"merged_4bit\",\n",
    "    #     tokenizer=tokenizer,\n",
    "    # )\n",
    "    model.save_pretrained_merged(\n",
    "        # f\"{project_root}/data/06_models/{user_id}/{pretrained_model_name}-tool-calling-sft/unsloth_lora\",\n",
    "        f\"{cwd}/data/06_models/{user_id}/{pretrained_model_name}-tool-calling-sft/unsloth_lora\",\n",
    "        save_method=\"lora\",\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError(\"Pushing to hub is not implemented yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a207b4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:40:16.210811Z",
     "iopub.status.busy": "2024-11-29T18:40:16.210259Z",
     "iopub.status.idle": "2024-11-29T18:40:16.219299Z",
     "shell.execute_reply": "2024-11-29T18:40:16.217215Z"
    },
    "papermill": {
     "duration": 0.071121,
     "end_time": "2024-11-29T18:40:16.222349",
     "exception": false,
     "start_time": "2024-11-29T18:40:16.151228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pad_token: <unk>\n",
      "tokenizer.padding_side: left\n"
     ]
    }
   ],
   "source": [
    "print('tokenizer.pad_token:', tokenizer.pad_token)\n",
    "print('tokenizer.padding_side:', tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7b56614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:40:16.314962Z",
     "iopub.status.busy": "2024-11-29T18:40:16.314477Z",
     "iopub.status.idle": "2024-11-29T18:40:16.321687Z",
     "shell.execute_reply": "2024-11-29T18:40:16.320053Z"
    },
    "papermill": {
     "duration": 0.06028,
     "end_time": "2024-11-29T18:40:16.323707",
     "exception": false,
     "start_time": "2024-11-29T18:40:16.263427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code_path = f\"{project_root}/src/training_tinyllama_for_tool_calling/services/agent.py\"\n",
    "code_path = f\"{cwd}/src/training_tinyllama_for_tool_calling/services/agent.py\"\n",
    "\n",
    "os.makedirs(Path(code_path).parent, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "720c4219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:40:16.400496Z",
     "iopub.status.busy": "2024-11-29T18:40:16.400192Z",
     "iopub.status.idle": "2024-11-29T18:40:16.410559Z",
     "shell.execute_reply": "2024-11-29T18:40:16.409560Z"
    },
    "papermill": {
     "duration": 0.049638,
     "end_time": "2024-11-29T18:40:16.412466",
     "exception": false,
     "start_time": "2024-11-29T18:40:16.362828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/mjschock/Projects/training-tinyllama-for-tool-calling/src/training_tinyllama_for_tool_calling/services/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $code_path\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "from typing import Dict, List\n",
    "\n",
    "import evaluate\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from mlflow.models import set_model\n",
    "from mlflow.pyfunc import ChatModel\n",
    "from mlflow.types.llm import (\n",
    "    ChatChoice,\n",
    "    ChatMessage,\n",
    "    ChatParams,\n",
    "    ChatResponse,\n",
    "    FunctionToolCallArguments,\n",
    "    ToolCall,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "project_root = os.getcwd()\n",
    "\n",
    "while not os.path.exists(os.path.join(project_root, \"register_prefect_flow.py\")):\n",
    "    project_root = os.path.dirname(project_root)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "max_seq_length = 4096\n",
    "# model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "# model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# model_name = \"data/06_models/model/lora\"\n",
    "# model_name = \"data/06_models/mjschock/TinyLlama-1.1B-Chat-v1.0_lora_sft\"\n",
    "# model_name = f\"{project_root}/data/06_models/mjschock/TinyLlama-1.1B-Chat-v1.0-tool-calling-sft/lora\"\n",
    "# model_name = f\"{project_root}/data/06_models/mjschock/TinyLlama-1.1B-Chat-v1.0-tool-calling-sft/lora\"\n",
    "\n",
    "class ModelClient:\n",
    "    def __init__(self):\n",
    "        user_id = \"mjschock\" # TODO: get this dynamically\n",
    "        pretrained_model_name = \"TinyLlama-1.1B-Chat-v1.0\"\n",
    "        model_name = f\"{project_root}/data/06_models/{user_id}/{pretrained_model_name}-tool-calling-sft/lora\"\n",
    "        # model_name = f\"{project_root}/data/06_models/{user_id}/{pretrained_model_name}-tool-calling-sft/unsloth_lora\" # TODO:Maybe this would work better for using the model rather than code path?\n",
    "\n",
    "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "            dtype=dtype,\n",
    "            load_in_4bit=load_in_4bit,\n",
    "            max_seq_length=max_seq_length,\n",
    "            model_name=model_name,\n",
    "        )\n",
    "\n",
    "        FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n",
    "\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def chat_completion_request(\n",
    "        self,\n",
    "        documents: list,\n",
    "        messages: list,\n",
    "        tools: list,\n",
    "    ):\n",
    "        # FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n",
    "\n",
    "        inputs = self.tokenizer.apply_chat_template(\n",
    "            add_generation_prompt=True,\n",
    "            conversation=messages,\n",
    "            documents=documents,\n",
    "            return_tensors=\"pt\",\n",
    "            tokenize=True,\n",
    "            tools=tools,\n",
    "        ).to(device)\n",
    "\n",
    "        outputs = self.model.generate(\n",
    "            do_sample=False,\n",
    "            input_ids=inputs,\n",
    "            max_new_tokens=256,\n",
    "            use_cache=True,\n",
    "            # temperature=0.0,\n",
    "        )\n",
    "\n",
    "        batch_decoded_outputs = self.tokenizer.batch_decode(outputs)\n",
    "\n",
    "        choices: List[ChatChoice] = []\n",
    "\n",
    "        for i in range(len(batch_decoded_outputs)):\n",
    "            response = batch_decoded_outputs[i][\n",
    "                len(self.tokenizer.decode(inputs[i])) :\n",
    "            ].replace(\n",
    "                self.tokenizer.eos_token, \"\"\n",
    "            )  # TODO: skip special tokens when decoding instead?\n",
    "\n",
    "            try:\n",
    "                response = json.loads(response)\n",
    "\n",
    "                finish_reason: str = response.get(\"finish_reason\")\n",
    "                tool_calls_json = response.get(\"tool_calls\")\n",
    "                tool_calls: List[ToolCall] = []\n",
    "\n",
    "                for tool_call_json in tool_calls_json:\n",
    "                    tool_call = ToolCall(\n",
    "                        function=FunctionToolCallArguments(\n",
    "                            arguments=tool_call_json.get(\"arguments\"),\n",
    "                            name=tool_call_json.get(\"name\"),\n",
    "                        ),\n",
    "                        id=tool_call_json.get(\"id\"),\n",
    "                        type=\"function\",\n",
    "                    )\n",
    "\n",
    "                    tool_calls.append(tool_call)\n",
    "\n",
    "                message: ChatMessage = ChatMessage(\n",
    "                    role=\"assistant\",\n",
    "                    tool_calls=tool_calls,\n",
    "                )\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                finish_reason: str = \"stop\"\n",
    "                message: ChatMessage = ChatMessage(\n",
    "                    role=\"assistant\",\n",
    "                    content=response,\n",
    "                )\n",
    "\n",
    "            choices.append(\n",
    "                ChatChoice(\n",
    "                    index=i,\n",
    "                    finish_reason=finish_reason,\n",
    "                    logprobs=None,\n",
    "                    message=message,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return ChatResponse(\n",
    "            choices=choices,\n",
    "        )\n",
    "\n",
    "\n",
    "class Agent(ChatModel):\n",
    "    def __init__(self):\n",
    "        # self.model_name = \"llama3.2:1b\"\n",
    "        self.client = None\n",
    "\n",
    "    def load_context(self, context):\n",
    "        # self.model_name = \"llama3.2:1b\"\n",
    "        # self.client = ollama.Client()\n",
    "        print('=== load_context ===')\n",
    "        print('context:', context)\n",
    "\n",
    "        self.client = ModelClient()\n",
    "\n",
    "    # the core method that needs to be implemented. this function\n",
    "    # will be called every time a user sends messages to our model\n",
    "    # @mlflow.trace(span_type=SpanType.AGENT)\n",
    "    def predict(self, context, messages: list[ChatMessage], params: ChatParams):\n",
    "        # instantiate the OpenAI client\n",
    "        # client = OpenAI()\n",
    "\n",
    "        # convert the messages to a format that the OpenAI API expects\n",
    "        messages = [m.to_dict() for m in messages]\n",
    "\n",
    "        print(\"params:\")\n",
    "        pprint(params.to_dict())\n",
    "\n",
    "        tools = params.tools or []\n",
    "\n",
    "        print(\"tools:\")\n",
    "        pprint(tools)\n",
    "\n",
    "        tools = [t.to_dict() for t in tools]\n",
    "\n",
    "        print(\"tools:\")\n",
    "        pprint(tools)\n",
    "\n",
    "        # call the OpenAI API\n",
    "        # response = client.chat.completions.create(\n",
    "        #     model=\"gpt-4o-mini\",\n",
    "        #     messages=messages,\n",
    "        #     # pass the tools in the request\n",
    "        #     tools=self.tools,\n",
    "        # )\n",
    "\n",
    "        response = self.client.chat_completion_request(\n",
    "            documents=[],  # we don't need documents for this example\n",
    "            messages=messages,\n",
    "            # tools=self.tools,\n",
    "            # tools=[],\n",
    "            tools=tools,\n",
    "        )\n",
    "\n",
    "        # return the result as a ChatResponse, as this\n",
    "        # is the expected output of the predict method\n",
    "        return ChatResponse.from_dict(response.to_dict())\n",
    "\n",
    "\n",
    "set_model(Agent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f296fea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:40:16.493060Z",
     "iopub.status.busy": "2024-11-29T18:40:16.492667Z",
     "iopub.status.idle": "2024-11-29T18:40:16.746876Z",
     "shell.execute_reply": "2024-11-29T18:40:16.745652Z"
    },
    "papermill": {
     "duration": 0.300428,
     "end_time": "2024-11-29T18:40:16.749178",
     "exception": false,
     "start_time": "2024-11-29T18:40:16.448750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34229"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "try:\n",
    "    del model\n",
    "\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del sft_trainer\n",
    "\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del tokenizer\n",
    "\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "365b6763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:40:16.850005Z",
     "iopub.status.busy": "2024-11-29T18:40:16.849684Z",
     "iopub.status.idle": "2024-11-29T18:41:12.582977Z",
     "shell.execute_reply": "2024-11-29T18:41:12.581881Z"
    },
    "papermill": {
     "duration": 55.795252,
     "end_time": "2024-11-29T18:41:12.585465",
     "exception": false,
     "start_time": "2024-11-29T18:40:16.790213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/29 10:40:16 INFO mlflow.pyfunc: Predicting on input example to validate output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/mjschock/Projects/training-tinyllama-for-tool-calling\n",
      "=== load_context ===\n",
      "context: <mlflow.pyfunc.model.PythonModelContext object at 0x768c23705de0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.5: Fast Llama patching. Transformers = 4.46.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce GTX 1050 Ti. Max memory: 3.94 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 6.1. CUDA Toolkit = 12.4.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: unsloth/tinyllama-chat-bnb-4bit can only handle sequence lengths of at most 2048.\n",
      "But with kaiokendev's RoPE scaling of 2.0, it can be magically be extended to 4096!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params:\n",
      "{'n': 1,\n",
      " 'stream': False,\n",
      " 'temperature': 1.0,\n",
      " 'tools': [{'function': {'description': 'Get the current weather',\n",
      "                         'name': 'get_current_weather',\n",
      "                         'parameters': {'properties': {'format': {'enum': ['celsius',\n",
      "                                                                           'fahrenheit'],\n",
      "                                                                  'type': 'string'},\n",
      "                                                       'location': {'description': 'The '\n",
      "                                                                                   'city '\n",
      "                                                                                   'and '\n",
      "                                                                                   'country, '\n",
      "                                                                                   'eg. '\n",
      "                                                                                   'San '\n",
      "                                                                                   'Francisco, '\n",
      "                                                                                   'USA',\n",
      "                                                                    'type': 'string'}},\n",
      "                                        'required': ['location', 'format'],\n",
      "                                        'type': 'object'},\n",
      "                         'strict': False},\n",
      "            'type': 'function'}]}\n",
      "tools:\n",
      "[ToolDefinition(function=FunctionToolDefinition(name='get_current_weather',\n",
      "                                                description='Get the current '\n",
      "                                                            'weather',\n",
      "                                                parameters=ToolParamsSchema(properties={'format': ParamProperty(type='string',\n",
      "                                                                                                                description=None,\n",
      "                                                                                                                enum=['celsius',\n",
      "                                                                                                                      'fahrenheit'],\n",
      "                                                                                                                items=None),\n",
      "                                                                                        'location': ParamProperty(type='string',\n",
      "                                                                                                                  description='The '\n",
      "                                                                                                                              'city '\n",
      "                                                                                                                              'and '\n",
      "                                                                                                                              'country, '\n",
      "                                                                                                                              'eg. '\n",
      "                                                                                                                              'San '\n",
      "                                                                                                                              'Francisco, '\n",
      "                                                                                                                              'USA',\n",
      "                                                                                                                  enum=None,\n",
      "                                                                                                                  items=None)},\n",
      "                                                                            type='object',\n",
      "                                                                            required=['location',\n",
      "                                                                                      'format'],\n",
      "                                                                            additionalProperties=None),\n",
      "                                                strict=False),\n",
      "                type='function')]\n",
      "tools:\n",
      "[{'function': {'description': 'Get the current weather',\n",
      "               'name': 'get_current_weather',\n",
      "               'parameters': {'properties': {'format': {'enum': ['celsius',\n",
      "                                                                 'fahrenheit'],\n",
      "                                                        'type': 'string'},\n",
      "                                             'location': {'description': 'The '\n",
      "                                                                         'city '\n",
      "                                                                         'and '\n",
      "                                                                         'country, '\n",
      "                                                                         'eg. '\n",
      "                                                                         'San '\n",
      "                                                                         'Francisco, '\n",
      "                                                                         'USA',\n",
      "                                                          'type': 'string'}},\n",
      "                              'required': ['location', 'format'],\n",
      "                              'type': 'object'},\n",
      "               'strict': False},\n",
      "  'type': 'function'}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c665024d564c06aa3fb9f0da07eee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/mjschock/Projects/training-tinyllama-for-tool-calling\n",
      "=== load_context ===\n",
      "context: <mlflow.pyfunc.model.PythonModelContext object at 0x768c23705d50>\n",
      "==((====))==  Unsloth 2024.11.5: Fast Llama patching. Transformers = 4.46.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce GTX 1050 Ti. Max memory: 3.94 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 6.1. CUDA Toolkit = 12.4.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params:\n",
      "{'n': 1,\n",
      " 'stream': False,\n",
      " 'temperature': 1.0,\n",
      " 'tools': [{'function': {'description': 'Get the current weather',\n",
      "                         'name': 'get_current_weather',\n",
      "                         'parameters': {'properties': {'format': {'enum': ['celsius',\n",
      "                                                                           'fahrenheit'],\n",
      "                                                                  'type': 'string'},\n",
      "                                                       'location': {'description': 'The '\n",
      "                                                                                   'city '\n",
      "                                                                                   'and '\n",
      "                                                                                   'country, '\n",
      "                                                                                   'eg. '\n",
      "                                                                                   'San '\n",
      "                                                                                   'Francisco, '\n",
      "                                                                                   'USA',\n",
      "                                                                    'type': 'string'}},\n",
      "                                        'required': ['location', 'format'],\n",
      "                                        'type': 'object'},\n",
      "                         'strict': False},\n",
      "            'type': 'function'}]}\n",
      "tools:\n",
      "[ToolDefinition(function=FunctionToolDefinition(name='get_current_weather',\n",
      "                                                description='Get the current '\n",
      "                                                            'weather',\n",
      "                                                parameters=ToolParamsSchema(properties={'format': ParamProperty(type='string',\n",
      "                                                                                                                description=None,\n",
      "                                                                                                                enum=['celsius',\n",
      "                                                                                                                      'fahrenheit'],\n",
      "                                                                                                                items=None),\n",
      "                                                                                        'location': ParamProperty(type='string',\n",
      "                                                                                                                  description='The '\n",
      "                                                                                                                              'city '\n",
      "                                                                                                                              'and '\n",
      "                                                                                                                              'country, '\n",
      "                                                                                                                              'eg. '\n",
      "                                                                                                                              'San '\n",
      "                                                                                                                              'Francisco, '\n",
      "                                                                                                                              'USA',\n",
      "                                                                                                                  enum=None,\n",
      "                                                                                                                  items=None)},\n",
      "                                                                            type='object',\n",
      "                                                                            required=['location',\n",
      "                                                                                      'format'],\n",
      "                                                                            additionalProperties=None),\n",
      "                                                strict=False),\n",
      "                type='function')]\n",
      "tools:\n",
      "[{'function': {'description': 'Get the current weather',\n",
      "               'name': 'get_current_weather',\n",
      "               'parameters': {'properties': {'format': {'enum': ['celsius',\n",
      "                                                                 'fahrenheit'],\n",
      "                                                        'type': 'string'},\n",
      "                                             'location': {'description': 'The '\n",
      "                                                                         'city '\n",
      "                                                                         'and '\n",
      "                                                                         'country, '\n",
      "                                                                         'eg. '\n",
      "                                                                         'San '\n",
      "                                                                         'Francisco, '\n",
      "                                                                         'USA',\n",
      "                                                          'type': 'string'}},\n",
      "                              'required': ['location', 'format'],\n",
      "                              'type': 'object'},\n",
      "               'strict': False},\n",
      "  'type': 'function'}]\n"
     ]
    }
   ],
   "source": [
    "# mlflow.set_experiment(\"chatmodel-quickstart\")\n",
    "# code_path = \"ollama_model.py\"\n",
    "# code_path = \"model.py\"\n",
    "# code_path = f\"{project_root}/src/training_tinyllama_for_tool_calling/services/agent.py\"\n",
    "# model = Model()\n",
    "\n",
    "# with mlflow.start_run(\n",
    "#     experiment_id=experiment.experiment_id,\n",
    "#     nested=True,\n",
    "# ):\n",
    "model_info = mlflow.pyfunc.log_model(\n",
    "    # \"ollama_model\",\n",
    "    \"model\",\n",
    "    python_model=code_path,\n",
    "    # python_model=model, # AttributeError: Can't get attribute 'unsloth_push_to_hub' on <module 'unsloth.save'\n",
    "    input_example={\n",
    "        # \"messages\": [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n",
    "        \"messages\": test_example_messages[0:1],\n",
    "        \"tools\": test_example_tools,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "057fcaee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:41:12.666139Z",
     "iopub.status.busy": "2024-11-29T18:41:12.665605Z",
     "iopub.status.idle": "2024-11-29T18:41:12.672991Z",
     "shell.execute_reply": "2024-11-29T18:41:12.672160Z"
    },
    "papermill": {
     "duration": 0.049032,
     "end_time": "2024-11-29T18:41:12.674861",
     "exception": false,
     "start_time": "2024-11-29T18:41:12.625829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs:/dbb314a0b654499bbaefe1897a2e41dc/model'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info.model_uri"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 202.029469,
   "end_time": "2024-11-29T18:41:15.547043",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/training-tinyllama-for-tool-calling.ipynb",
   "output_path": "notebooks/training-tinyllama-for-tool-calling.output.ipynb",
   "parameters": {},
   "start_time": "2024-11-29T18:37:53.517574",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0da894f6e04f47c4b976a5095d7796ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "31f1d0927e8742daaeb7a43fc0573dd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ee97c11d146a49058518343f33165dbf",
       "placeholder": "​",
       "style": "IPY_MODEL_b80f3a611ea84cfb8df4ac68090fbac9",
       "tabbable": null,
       "tooltip": null,
       "value": " 7/7 [00:00&lt;00:00, 294.89it/s]"
      }
     },
     "366b1d959999445d82edeb1884d967ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_54ba0ffec6bc49a699f2dffba395c88e",
       "placeholder": "​",
       "style": "IPY_MODEL_41c0e29e92b54d32b0c7b3d0baf62c30",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "3809a5e0227a4c6bb065eac2adda10b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c1f6ffe75cc44b03ad0c9c23b2225c49",
       "placeholder": "​",
       "style": "IPY_MODEL_0da894f6e04f47c4b976a5095d7796ad",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 12.00 examples/s]"
      }
     },
     "41c0e29e92b54d32b0c7b3d0baf62c30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "43fb1d4a62d94a5697f7101df1696479": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4420e5acc5894183b5f85b2a87ab199b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b95df7cb952642148a73199edb9913b5",
       "placeholder": "​",
       "style": "IPY_MODEL_52cb3a2f96b94e80816fe1d7c115f052",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading artifacts: 100%"
      }
     },
     "444c83b87521404aabd45060698f924b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "475a629ab0ec4aceb58f04093d35be3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d33ebbbf88c8491a9ec11331ae9983a6",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bf9ad5ebfa8f47d2ba754a383276dc62",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "52cb3a2f96b94e80816fe1d7c115f052": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "54ba0ffec6bc49a699f2dffba395c88e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "595e5f51177e47a9bc2eded7b3f074fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "64c665024d564c06aa3fb9f0da07eee9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4420e5acc5894183b5f85b2a87ab199b",
        "IPY_MODEL_e3fcb83361ba4333a2fe7da69a6ce1a5",
        "IPY_MODEL_31f1d0927e8742daaeb7a43fc0573dd5"
       ],
       "layout": "IPY_MODEL_444c83b87521404aabd45060698f924b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "92b6da95c7b44e88a7ab6611986afbae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_366b1d959999445d82edeb1884d967ec",
        "IPY_MODEL_475a629ab0ec4aceb58f04093d35be3b",
        "IPY_MODEL_3809a5e0227a4c6bb065eac2adda10b5"
       ],
       "layout": "IPY_MODEL_d678d18f91274dec88217c30be1d6e76",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b80f3a611ea84cfb8df4ac68090fbac9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b95df7cb952642148a73199edb9913b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf9ad5ebfa8f47d2ba754a383276dc62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c1f6ffe75cc44b03ad0c9c23b2225c49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d33ebbbf88c8491a9ec11331ae9983a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d678d18f91274dec88217c30be1d6e76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3fcb83361ba4333a2fe7da69a6ce1a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_43fb1d4a62d94a5697f7101df1696479",
       "max": 7.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_595e5f51177e47a9bc2eded7b3f074fd",
       "tabbable": null,
       "tooltip": null,
       "value": 7.0
      }
     },
     "ee97c11d146a49058518343f33165dbf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}